<!DOCTYPE html>




<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <meta property="og:image" content="/assets/img/post7/2d_plot_burger.png"/>
    
    
    <link rel="stylesheet" type="text/css" href="/assets/css/syntax_highlight.css">
    <link rel="stylesheet" type="text/css" href="/assets/css/main.css">
    <link rel="alternate" type="application/rss+xml" title="RSS Feed" href="atom.xml" />

    <!-- MathJax Configuration -->
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true
          }
        });
    </script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

    <script>
      function show_tag_section(tag) {
        // Hide all other tag divs
        document.getElementById('all_posts').style.display = 'none';
        var tag_divs = document.getElementsByClassName('by_tag');
        var i;
        for (var i = 0; i < tag_divs.length; i++) {
          tag_divs[i].style.display = 'none';
        }
        // Show the one we want
        document.getElementById(tag).style.display = 'block';
      }
    </script>
    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico">
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Solving the 1D Burgers’ Equation with Physics-Informed Neural Networks (PINNs) | Marcos Benício</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="Solving the 1D Burgers’ Equation with Physics-Informed Neural Networks (PINNs)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="This project aims to solve the one-dimensional Burgers’ equation using a Physics-Informed Neural Network (PINN). The Burgers’ equation is a fundamental partial differential equation (PDE) in applied mathematics, used to model phenomena in fluid mechanics, nonlinear acoustics, and gas dynamics" />
<meta property="og:description" content="This project aims to solve the one-dimensional Burgers’ equation using a Physics-Informed Neural Network (PINN). The Burgers’ equation is a fundamental partial differential equation (PDE) in applied mathematics, used to model phenomena in fluid mechanics, nonlinear acoustics, and gas dynamics" />
<link rel="canonical" href="http://localhost:4000/2023/07/15/pinn-burgers.html" />
<meta property="og:url" content="http://localhost:4000/2023/07/15/pinn-burgers.html" />
<meta property="og:site_name" content="Marcos Benício" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-07-15T00:00:00-03:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Solving the 1D Burgers’ Equation with Physics-Informed Neural Networks (PINNs)" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-07-15T00:00:00-03:00","datePublished":"2023-07-15T00:00:00-03:00","description":"This project aims to solve the one-dimensional Burgers’ equation using a Physics-Informed Neural Network (PINN). The Burgers’ equation is a fundamental partial differential equation (PDE) in applied mathematics, used to model phenomena in fluid mechanics, nonlinear acoustics, and gas dynamics","headline":"Solving the 1D Burgers’ Equation with Physics-Informed Neural Networks (PINNs)","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2023/07/15/pinn-burgers.html"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/img/profile_photo.png"}},"url":"http://localhost:4000/2023/07/15/pinn-burgers.html"}</script>
<!-- End Jekyll SEO tag -->

  </head>
  <body onload="show_tag_section('all_posts')">

    <div class="header">

      <!-- Large header banner on left for large display widths -->
      <div class="big_header">

        <!-- Name -->
        <div class="name_group">
          <h1><a href="/">Marcos Benício</a></h1>
        </div>

        <!-- <a href=""><img src="/assets/img/profile_photo.png" alt="Logo" class="center_img" ></a>-->
        <a href="/"><img src="/assets/img/profile_photo.png" alt="Logo" class="center_img" ></a>
        <!--<a href=""><img src="/assets/img/profile_photo.png" alt="Logo" class="center_img" ></a>-->



        <!-- Position + company -->
        <div class="link_group">

          <div class="row">
              <div class="col1">
                <span> M.sc in Physics</span>
              </div>
          </div>

          <div class="row">
            <!-- <a href=""-->
              <div class="col1">
                <img src="/assets/img/brazil_icon.png" height="30" width="30">
                <!-- <span>  </span>-->
              </div>
            </a>
          </div>

          <div class="row">
            <div class="col1">
              <img src="/assets/img/place_icon_light.png" height="16" width="16">
              <span> Niterói, RJ </span>
            </div>
          </div>

        </div>

        <!-- Badges/links -->
        <div class="link_group">

          <div class="row">
            <a href="https://github.com/marcosbenicio">
              <div class="col2">
                <img src="/assets/img/github_icon_light.png" height="16" width="16">
                <span> Github </span>
              </div>
            </a>
            <a href="https://linkedin.com/in/marcos-benício-de-andrade-alonso-415a5b16b">
              <div class="col2">
                <img src="/assets/img/linkedin_icon_light.png" height="16" width="16">
                <span> LinkedIn </span>
              </div>
            </a>
          </div>

          <div class="row">
            <a href="mailto:marcosbenicio0102@gmail.com">
              <div class="col2">
                <img src="/assets/img/email_icon_light.png" height="16" width="16">
                <span> Email </span>
              </div>
            </a>
            <a href="/assets/files/resume.pdf">
              <div class="col2">
                <img src="/assets/img/cv_icon_light.png" height="16" width="16">
                <span> Resume </span>
              </div>
            </a>
          </div>

        </div>

      </div>

      <!-- Smaller header banner on top for small display widths -->
      <div class="small_header">

        <!-- Name -->
        <div class="small_header_box">
          <div class="name_header_box">
            <div class="name_header_img">
              <a href="/">
                <img src="/assets/img/profile_photo.png" alt="Logo" height="60">
              </a>
            </div>
            <div class="name_header_name">
              <h1><a href="/">Marcos Benício</a></h1>
            </div>
          </div>
        </div>

        <!-- Position + Company -->
        <div class="small_header_box">
          <div class="row">
            <div class="col1">
              <span> M.sc in Physics </span>
            </div>
          </div>
          <div class="row">
            <div class="col1">
             <!-- <a href=""> -->
                  <img src="/assets/img/brazil_icon.png" height="30" width="30">
                  <!-- <span>  </span> -->
              </a>
            </div>
          </div>
        </div>

        <!-- Badges/links -->
        <div class="small_header_box">
                <div class="row">
                  <a href="https://github.com/marcosbenicio">
                    <div class="col2">
                      <img src="/assets/img/github_icon_light.png" height="16" width="16">
                      <span> Github </span>
                    </div>
                  </a>
                  <a href="https://linkedin.com/in/marcos-benício-de-andrade-alonso-415a5b16b">
                    <div class="col2">
                      <img src="/assets/img/linkedin_icon_light.png" height="16" width="16">
                      <span> LinkedIn </span>
                    </div>
                  </a>
                </div>

                <div class="row">
                  <a href="mailto:marcosbenicio0102@gmail.com">
                    <div class="col2">
                      <img src="/assets/img/email_icon_light.png" height="16" width="16">
                      <span> Email </span>
                    </div>
                  </a>
                  <a href="/assets/files/resume.pdf">
                    <div class="col2">
                      <img src="/assets/img/cv_icon_light.png" height="16" width="16">
                      <span> Resume </span>
                    </div>
                  </a>
                </div>
        </div>

      </div>

    </div>

    <!-- Page content -->
    <div class="content">

      <h1>Solving the 1D Burgers' Equation with Physics-Informed Neural Networks (PINNs)</h1>
<p class="meta">15 Jul 2023 - Tags: Multilayer Perceptron and Physics-Informed Neural Network</p>

<div class="button_container">
  
    <a href="https://github.com/marcosbenicio/pinns/blob/main/pinn_burgers.ipynb">
      <div class="button_link">
        View on<br /><strong>Github</strong>
      </div>
    </a>
  
  
  
</div>


<div class="post">
  <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">cProfile</span>
<span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">scipy.optimize</span> <span class="kn">import</span> <span class="n">fmin_l_bfgs_b</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">matplotlib.gridspec</span> <span class="kn">import</span> <span class="n">GridSpec</span>
<span class="kn">from</span> <span class="n">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>

<span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="n">keras</span> <span class="kn">import</span> <span class="n">callbacks</span> <span class="k">as</span> <span class="n">callbacks_module</span>
<span class="kn">from</span> <span class="n">keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="n">keras.layers</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Layer</span>
<span class="kn">from</span> <span class="n">keras.losses</span> <span class="kn">import</span> <span class="n">Loss</span><span class="p">,</span> <span class="n">mse</span>
<span class="kn">from</span> <span class="n">keras.optimizers</span> <span class="kn">import</span> <span class="n">Optimizer</span><span class="p">,</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="n">keras.metrics</span> <span class="kn">import</span> <span class="n">Mean</span>
<span class="kn">from</span> <span class="n">keras.utils</span> <span class="kn">import</span>  <span class="n">plot_model</span>

<span class="kn">from</span> <span class="n">keras.engine</span> <span class="kn">import</span> <span class="n">data_adapter</span>
<span class="kn">import</span> <span class="n">keras.backend</span>

<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
</code></pre></div></div>

<h1 id="pinn-one-dimensional-burger-equation">PINN: One-Dimensional Burger Equation</h1>

<p>The Burgers’ equation is a fundamental partial differential equation (PDE) that arises in various areas of applied mathematics, such as fluid mechanics, nonlinear acoustics, and gas dynamics. The equation describes the evolution of a scalar field (like velocity, temperature, or density) that experiences both nonlinear convection and diffusion.</p>

<p>In its one-dimensional, unsteady, and inviscid form, the Burgers’ equation is given by:</p>

\[\frac{\partial u}{\partial t} + u \frac{\partial u}{\partial x} = \nu \frac{\partial^2 u}{\partial x^2}\]

<p>Here, u(x, t) is the dependent variable (e.g., velocity), x is the spatial variable, t is the time variable, and ν is the kinematic viscosity coefficient. The first term on the left-hand side represents the time evolution, the second term represents the nonlinear convection, and the term on the right-hand side represents the diffusion or dissipation.</p>

<p>In the specific case considered in the provided code, the Burgers’ equation is solved with the following conditions:</p>

<ul>
  <li><strong>Domain</strong>: The spatial domain is $x \in [1,-1]$, and the time domain is $t \in [0,1]$, the problem is being solved within this rectangular domain.</li>
  <li><strong>Initial Condition</strong>: $u(0, x) = -\sin(\pi x)$ where $ x \in [-1, 1]$. This describes the initial state of the dependent variable $u(x, t)$ at time $t = 0$.</li>
  <li><strong>Boundary conditions</strong>:u(t, -1) = u(t, 1) = 0, where $t \in [0,1]$. These conditions enforce that the dependent variable $u(x, t)$ is equal to zero at the boundaries $x = -1$ and $x = 1$ for all times t.</li>
</ul>

<p>The goal is to train a physics-informed neural network (PINN) to approximate the solution $u(x, t)$ of the Burgers’ equation under these conditions. The PINN is trained to minimize the residuals of the PDE, initial conditions, and boundary conditions by using randomly sampled points within the domain and points satisfying the initial and boundary conditions.</p>

<h1 id="dense-neural-network-dnn-model">Dense Neural Network (DNN): Model</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">DNN</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>
                 <span class="n">layer_units</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span><span class="mi">32</span><span class="p">],</span>
                 <span class="n">output_unit</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                 <span class="n">activation_func</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">'</span><span class="s">tanh</span><span class="sh">'</span><span class="p">,</span>
                 <span class="n">initializer</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">"</span><span class="s">he_normal</span><span class="sh">"</span><span class="p">,</span>
                 <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">DNN</span><span class="sh">"</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Initialize the DNN (Deep Neural Network) layer.

        Args:
            layer_units: A list of integers representing the number of units in each hidden layer .
            output_unit: An integer representing the number of units in the output layer .
            activation_func: A string representing the activation function used in the hidden layers .
            initializer: A string representing the kernel initializer used for the layers .
            name: A string representing the name of the layer.
        </span><span class="sh">"""</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">units</span> <span class="o">=</span> <span class="n">layer_units</span>
        <span class="n">self</span><span class="p">.</span><span class="n">output_unit</span> <span class="o">=</span> <span class="n">output_unit</span>
        <span class="n">self</span><span class="p">.</span><span class="n">activation_func</span> <span class="o">=</span> <span class="n">activation_func</span>
        <span class="n">self</span><span class="p">.</span><span class="n">initializer</span> <span class="o">=</span> <span class="n">initializer</span>

        <span class="c1"># Hidden layers
</span>        <span class="n">self</span><span class="p">.</span><span class="n">hidden_layer</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">unit</span> <span class="ow">in</span> <span class="n">layer_units</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">hidden_layer</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">unit</span><span class="p">,</span>
                                           <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">initializer</span><span class="p">,</span>
                                           <span class="n">activation</span><span class="o">=</span><span class="n">activation_func</span><span class="p">,</span>
                                           <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">Hidden_{}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">count</span><span class="p">)))</span>
            <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Output layer
</span>        <span class="n">self</span><span class="p">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">output_unit</span><span class="p">,</span>
                                  <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">initializer</span><span class="p">,</span>
                                  <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">Output</span><span class="sh">"</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Compute the forward pass of the DNN layer.

        Args:
            x: A tensor of shape (batch_size, input_dim), where input_dim is the dimension of 
            the input features.

        Returns:
            x: A tensor of shape (batch_size, output_unit), containing the output of the DNN layer.
        </span><span class="sh">"""</span>

        <span class="k">for</span> <span class="n">hidden</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">hidden_layer</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="nf">hidden</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">output_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>
</code></pre></div></div>

<h1 id="automatic-diff-layer">Automatic Diff: Layer</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">AutomaticDiff</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dnn</span><span class="p">:</span> <span class="n">DNN</span><span class="p">,</span>
                         <span class="n">nu</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> 
                         <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">'</span><span class="s">AutomaticDiff</span><span class="sh">'</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Initialize the AutomaticDiff layer.
        
        Args:
            dnn: A deep neural network (DNN) used for computing derivatives.
            nu: A float representing the viscosity coefficient in Burgers</span><span class="sh">'</span><span class="s"> equation.
            name: A string representing the name of this layer. Defaults to </span><span class="sh">'</span><span class="s">AutomaticDiff</span><span class="sh">'</span><span class="s">.
        </span><span class="sh">"""</span>

        <span class="n">self</span><span class="p">.</span><span class="n">dnn</span> <span class="o">=</span> <span class="n">dnn</span>
        <span class="n">self</span><span class="p">.</span><span class="n">nu</span> <span class="o">=</span> <span class="n">nu</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">xt</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Compute the residual of Burgers</span><span class="sh">'</span><span class="s"> equation using the input tensor xt.
        
        This method computes the first and second derivatives of the DNN with respect to the input tensor, 
        and then calculates the residual of Burgers</span><span class="sh">'</span><span class="s"> equation using these derivatives.

        Args:
            xt: A tensor representing the input data (spatial and temporal points).

        Returns:
            residual: A tensor representing the residual of Burgers</span><span class="sh">'</span><span class="s"> equation.
        </span><span class="sh">"""</span>
        <span class="c1"># Jacobian outputs shape: (batch, units, input_size)
</span>        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nc">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">gg</span><span class="p">:</span>
            <span class="n">gg</span><span class="p">.</span><span class="nf">watch</span><span class="p">(</span><span class="n">xt</span><span class="p">)</span>
            <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nc">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">g</span><span class="p">:</span>
                <span class="n">g</span><span class="p">.</span><span class="nf">watch</span><span class="p">(</span><span class="n">xt</span><span class="p">)</span>
                <span class="n">u</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">dnn</span><span class="p">(</span><span class="n">xt</span><span class="p">)</span>  

            <span class="n">du_dxt</span> <span class="o">=</span>  <span class="n">g</span><span class="p">.</span><span class="nf">batch_jacobian</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">xt</span><span class="p">)</span>
            <span class="n">du_dx</span>  <span class="o">=</span> <span class="n">du_dxt</span><span class="p">[:,:,</span><span class="mi">0</span><span class="p">]</span>            
            <span class="n">du_dt</span> <span class="o">=</span> <span class="n">du_dxt</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">]</span> 

        <span class="n">d2u_dx2</span> <span class="o">=</span> <span class="n">gg</span><span class="p">.</span><span class="nf">batch_jacobian</span><span class="p">(</span><span class="n">du_dx</span><span class="p">,</span> <span class="n">xt</span><span class="p">)[:,:,</span><span class="mi">0</span><span class="p">]</span> 


        <span class="n">residual</span> <span class="o">=</span> <span class="n">du_dt</span> <span class="o">+</span> <span class="n">u</span><span class="o">*</span><span class="n">du_dx</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">nu</span><span class="o">*</span><span class="n">d2u_dx2</span>
        <span class="k">return</span> <span class="n">residual</span>
</code></pre></div></div>

<h1 id="optimizer-l-bfgs-b--class">Optimizer L-BFGS-B : Class</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">L_BFGS_B</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> 
                 <span class="n">model</span> <span class="p">,</span> 
                 <span class="n">x_train</span><span class="p">,</span> 
                 <span class="n">y_train</span><span class="p">,</span> 
                 <span class="n">loss_func</span><span class="p">,</span>
                 <span class="n">factr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e7</span><span class="p">,</span> 
                 <span class="n">m</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
                 <span class="n">maxls</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
                 <span class="n">maxiter</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">5000</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Initialize the L-BFGS-B optimizer with given model, data, loss function, and optimization parameters.

        Args:
            model: The model to be optimized.
            x_train: The input data (features) for training.
            y_train: The output data (labels) for training.
            loss_func: The loss function to be minimized during training.
            factr: The optimization parameter for L-BFGS-B (default: 1e7).
            m: The number of limited memory vectors for L-BFGS-B (default: 50).
            maxls: The maximum number of line search steps for L-BFGS-B (default: 50).
            maxiter: The maximum number of iterations for L-BFGS-B (default: 5000).
        </span><span class="sh">"""</span>
   
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="n">self</span><span class="p">.</span><span class="n">loss_func</span> <span class="o">=</span> <span class="n">loss_func</span>
        <span class="n">self</span><span class="p">.</span><span class="n">loss_tracker</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="n">self</span><span class="p">.</span><span class="n">current_step</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">x_train</span> <span class="o">=</span> <span class="p">[</span> <span class="n">tf</span><span class="p">.</span><span class="nf">constant</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_train</span> <span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">y_train</span> <span class="o">=</span> <span class="p">[</span> <span class="n">tf</span><span class="p">.</span><span class="nf">constant</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">y_train</span> <span class="p">]</span>

        <span class="c1"># Store optimization parameters
</span>        <span class="n">self</span><span class="p">.</span><span class="n">factr</span> <span class="o">=</span> <span class="n">factr</span>
        <span class="n">self</span><span class="p">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">m</span>
        <span class="n">self</span><span class="p">.</span><span class="n">maxls</span> <span class="o">=</span> <span class="n">maxls</span> 
        <span class="n">self</span><span class="p">.</span><span class="n">maxiter</span> <span class="o">=</span> <span class="n">maxiter</span>
        <span class="n">self</span><span class="p">.</span><span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">loss</span><span class="sh">'</span><span class="p">]</span>

        <span class="c1"># Initialize the progress bar for displaying optimization progress
</span>        <span class="n">self</span><span class="p">.</span><span class="n">progbar</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="nc">ProgbarLogger</span><span class="p">(</span>
            <span class="n">count_mode</span><span class="o">=</span><span class="sh">'</span><span class="s">steps</span><span class="sh">'</span><span class="p">,</span> <span class="n">stateful_metrics</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">metrics</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">progbar</span><span class="p">.</span><span class="nf">set_params</span><span class="p">(</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">verbose</span><span class="sh">'</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">epochs</span><span class="sh">'</span><span class="p">:</span><span class="n">self</span><span class="p">.</span><span class="n">maxiter</span><span class="p">,</span> <span class="sh">'</span><span class="s">steps</span><span class="sh">'</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">metrics</span><span class="sh">'</span><span class="p">:</span><span class="n">self</span><span class="p">.</span><span class="n">metrics</span><span class="p">})</span>
   
    <span class="k">def</span> <span class="nf">set_weights</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weights_1d</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Set the model</span><span class="sh">'</span><span class="s">s weights using a 1D array of weights.

        Args:
            weights_1d: A 1D numpy array representing the weights of the model.
        </span><span class="sh">"""</span>

        <span class="c1">#Set the model's weights using a 1D array of weights
</span>        <span class="n">weights_shapes</span> <span class="o">=</span> <span class="p">[</span> <span class="n">w</span><span class="p">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">get_weights</span><span class="p">()</span> <span class="p">]</span>
        <span class="n">n</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span> <span class="n">np</span><span class="p">.</span><span class="nf">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">shape</span> <span class="ow">in</span> <span class="n">weights_shapes</span> <span class="p">]</span> 
        <span class="n">partition</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">cumsum</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> 
        <span class="n">weights</span> <span class="o">=</span> <span class="p">[</span> <span class="n">weights_1d</span><span class="p">[</span><span class="n">from_part</span><span class="p">:</span><span class="n">to_part</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">from_part</span><span class="p">,</span> <span class="n">to_part</span><span class="p">,</span> <span class="n">shape</span> 
                        <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">partition</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">partition</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">weights_shapes</span><span class="p">)</span> <span class="p">]</span>
                        
        <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">set_weights</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
    
    <span class="nd">@tf.function</span>
    <span class="k">def</span> <span class="nf">tf_evaluate</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Compute the model</span><span class="sh">'</span><span class="s">s loss and gradients for the given input (x) and output (y) tensors.

        Args:
            x: Input tensor.
            y: Output tensor.

        Returns:
            loss: The computed loss.
            grads: The computed gradients.
        </span><span class="sh">"""</span>
        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nc">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">loss_func</span><span class="p">(</span><span class="n">y</span><span class="p">,</span>  <span class="n">y_pred</span><span class="p">)</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="p">.</span><span class="nf">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">trainable_weights</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">grads</span>
    
    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weights_1d</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Evaluate the model</span><span class="sh">'</span><span class="s">s loss and gradients using the given 1D array of weights.

        Args:
            weights_1d: A 1D numpy array representing the weights of the model.

        Returns:
            loss: The computed loss.
            grads_concat: The computed gradients concatenated as a 1D numpy array.
        </span><span class="sh">"""</span>
        <span class="c1"># Evaluate the model's loss and gradients using the given 1D array of weights
</span>        <span class="n">self</span><span class="p">.</span><span class="nf">set_weights</span><span class="p">(</span><span class="n">weights_1d</span><span class="p">)</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">tf_evaluate</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">x_train</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">y_train</span><span class="p">)</span>

        <span class="c1"># Convert the loss and gradients to numpy arrays for use with the L-BFGS-B optimizer
</span>        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="p">.</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">float64</span><span class="sh">'</span><span class="p">)</span> 
        <span class="n">grads_concat</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">([</span> <span class="n">g</span><span class="p">.</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">flatten</span><span class="p">()</span> <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">grads</span> <span class="p">]).</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">float64</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">loss_tracker</span> <span class="o">=</span> <span class="n">loss</span>
        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">grads_concat</span>
    
    <span class="k">def</span> <span class="nf">callback</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="n">_</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Callback function to execute custom actions during optimization.

        Args:
            _: Unused argument for compatibility with the optimizer</span><span class="sh">'</span><span class="s">s callback signature.
        </span><span class="sh">"""</span>

        <span class="c1"># Update the progress bar at the specified interval
</span>        <span class="n">update_interval</span> <span class="o">=</span> <span class="mi">1000</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">current_step</span> <span class="o">%</span> <span class="n">update_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">progbar</span><span class="p">.</span><span class="nf">on_epoch_begin</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">current_step</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">loss_tracker</span>
            <span class="n">self</span><span class="p">.</span><span class="n">progbar</span><span class="p">.</span><span class="nf">on_epoch_end</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">current_step</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">loss</span><span class="sh">"</span><span class="p">:</span><span class="n">loss</span><span class="p">})</span>
            
        <span class="n">self</span><span class="p">.</span><span class="n">current_step</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Train the model using the L-BFGS-B optimization algorithm.
        </span><span class="sh">"""</span>

        <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">x_train</span><span class="p">)</span>
        <span class="n">initial_weights</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">([</span> <span class="n">w</span><span class="p">.</span><span class="nf">flatten</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">get_weights</span><span class="p">()</span> <span class="p">])</span>
        
        <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Optimizer: L-BFGS-B (maxiter={})</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">maxiter</span><span class="p">))</span>

        <span class="n">self</span><span class="p">.</span><span class="n">progbar</span><span class="p">.</span><span class="nf">on_train_begin</span><span class="p">()</span>
        <span class="c1"># Train the model using L-BFGS-B optimization
</span>        <span class="nf">fmin_l_bfgs_b</span><span class="p">(</span>  <span class="n">func</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">evaluate</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="n">initial_weights</span><span class="p">,</span> <span class="n">factr</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">factr</span><span class="p">,</span>
                        <span class="n">m</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">m</span><span class="p">,</span> <span class="n">maxls</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">maxls</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">maxiter</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">callback</span> <span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">progbar</span><span class="p">.</span><span class="nf">on_train_end</span><span class="p">()</span>
</code></pre></div></div>

<h1 id="physics-informed-neural-network-pinn-model">Physics Informed Neural Network (PINN): Model</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">PINN</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>
                  <span class="n">dnn</span><span class="p">:</span> <span class="n">DNN</span><span class="p">,</span>
                  <span class="n">nu</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.01</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">,</span>
                  <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span>  <span class="sh">'</span><span class="s">PINN</span><span class="sh">'</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="p">)</span>

        <span class="sh">"""</span><span class="s">
        Initialize the Physics-Informed Neural Network (PINN) model.

        Args:
            dnn (DNN): A deep neural network object to use as the base model.
            nu (float, optional): The parameter nu used in the PDE equation. Defaults to 0.01/np.pi.
            name (str, optional): The name of the model. Defaults to </span><span class="sh">'</span><span class="s">PINN</span><span class="sh">'</span><span class="s">.
        </span><span class="sh">"""</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">dnn</span> <span class="o">=</span> <span class="n">dnn</span>
        <span class="n">self</span><span class="p">.</span><span class="n">auto_diff</span> <span class="o">=</span> <span class="nc">AutomaticDiff</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">dnn</span><span class="p">,</span> <span class="n">nu</span><span class="p">)</span>


    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">metrics</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Return the list of loss trackers used in the model.
        </span><span class="sh">"""</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nf">hasattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="sh">'</span><span class="s">loss_tracker</span><span class="sh">'</span><span class="p">):</span>
            <span class="n">self</span><span class="p">.</span><span class="n">loss_tracker</span> <span class="o">=</span> <span class="nc">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">loss</span><span class="sh">"</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="n">loss_tracker</span><span class="p">]</span> 

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x_train</span><span class="p">):</span> 
        <span class="sh">"""</span><span class="s">
        Compute the model outputs for the given inputs.

        Args:
            x_train (tuple): A tuple containing the input data for equation, initial conditions, 
            and boundary conditions.

        Returns:
            tuple: The computed residuals, initial conditions, and boundary conditions.
        </span><span class="sh">"""</span>     

        <span class="n">xt</span><span class="p">,</span> <span class="n">xt_0</span><span class="p">,</span> <span class="n">xt_bnd</span> <span class="o">=</span> <span class="n">x_train</span>

        <span class="n">r</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">auto_diff</span><span class="p">(</span><span class="n">xt</span><span class="p">)</span>
        <span class="n">u_0</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">dnn</span><span class="p">(</span><span class="n">xt_0</span><span class="p">)</span>
        <span class="n">u_bnd</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">dnn</span><span class="p">(</span><span class="n">xt_bnd</span><span class="p">)</span>
        
        <span class="nf">return </span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">u_0</span><span class="p">,</span> <span class="n">u_bnd</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Train the model for one step using the given input and target data.

        Args:
            data (tuple): A tuple containing the input data and target data.

        Returns:
            dict: A dictionary containing the loss value for this training step.
        </span><span class="sh">"""</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">_process_step</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    
    <span class="nd">@tf.function</span>
    <span class="k">def</span> <span class="nf">tf_evaluate_loss_grads</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Evaluate the loss and gradients for the given input and target data.

        Args:
            x (tf.Tensor): The input data.
            y (tf.Tensor): The target data.

        Returns:
            tuple: The loss and gradients for the given input and target data.
        </span><span class="sh">"""</span>
        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nc">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="nf">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">compute_loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="p">.</span><span class="nf">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">trainable_weights</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">grads</span>
    
    <span class="c1"># Helper function to process one batch of data
</span>    <span class="k">def</span> <span class="nf">_process_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Helper function to process one batch of data.

        Args:
            data (tuple): A tuple containing the input data and target data.

        Returns:
            dict: A dictionary containing the loss value for this training step.
        </span><span class="sh">"""</span>
        <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">data</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">tf_evaluate_loss_grads</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
        <span class="c1">#if no other optimizer is choose and use_l_bfgs_b_optimizer = True
</span>        <span class="c1"># then self.optimizer = None and this is skipped
</span>        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span> <span class="o">!=</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">apply_gradients</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">trainable_weights</span><span class="p">))</span>

        <span class="c1"># Update the loss trackers
</span>        <span class="n">self</span><span class="p">.</span><span class="n">loss_tracker</span><span class="p">.</span><span class="nf">update_state</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    
        <span class="k">return</span> <span class="p">{</span><span class="sh">"</span><span class="s">loss</span><span class="sh">"</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">loss_tracker</span><span class="p">.</span><span class="nf">result</span><span class="p">()}</span>
    
    <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Compute the loss between the predicted and target values.

        Args:
            y_train (tf.Tensor): The target data.
            y_pred (tf.Tensor): The predicted data.

        Returns:
            tf.Tensor: The computed loss.
        </span><span class="sh">"""</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="nf">mse</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">loss</span>
        

    <span class="k">def</span> <span class="nf">custom_fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">shuffle</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> 
                    <span class="n">use_l_bfgs_b_optimizer</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">factr</span><span class="o">=</span><span class="mf">1e7</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">maxls</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">5000</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Custom fit function for the PINN model. This method allows the use of the L-BFGS-B optimizer, 
        which is a popular choice for solving partial differential equations with neural networks due 
        to its ability to handle large-scale optimization problems efficiently. By providing the option 
        to use the L-BFGS-B optimizer, this custom fit function enables better convergence and potentially 
        faster training for the PINN model.

        The input data (x) and target data (y) should be provided as tuples of tensors, where each element 
        in the tuple corresponds to a specific type of training data:

        x_train = (xt, xt_0, xt_bnd)
        y_train = (r, u_0, u_bnd)

        Args:
            x (tuple): The input data as a tuple of tensors (xt, xt_0, xt_bnd).
            y (tuple): The target data as a tuple of tensors (r, u_0, u_bnd).
            epochs (int, optional): The number of epochs to train the model. Defaults to 1.
            batch_size (int, optional): The batch size to use during training. Defaults to None.
            shuffle (bool, optional): Whether to shuffle the data before each epoch. Defaults to True.
            use_l_bfgs_b_optimizer (bool, optional): Whether to use the L-BFGS-B optimizer for training. 
            Defaults to True.
            factr (float, optional): The L-BFGS-B factr parameter. Defaults to 1e7.
            m (int, optional): The L-BFGS-B m parameter. Defaults to 50.
            maxls (int, optional): The L-BFGS-B maxls parameter. Defaults to 50.
            maxiter (int, optional): The L-BFGS-B maxiter parameter. Defaults to 5000.

        Returns:
            if use_l_bfgs_b_optimizer = False return tf.keras.callbacks.History: 
                A History object that records the training loss values.
        </span><span class="sh">"""</span>
        
        <span class="k">if</span> <span class="n">use_l_bfgs_b_optimizer</span><span class="p">:</span>
            <span class="c1"># Custom L_BFGS_B  Optimizer
</span>            <span class="n">l_bfgs_b_optimizer</span> <span class="o">=</span> <span class="nc">L_BFGS_B</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">self</span><span class="p">,</span> <span class="n">x_train</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y_train</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">loss_func</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">compute_loss</span><span class="p">,</span> 
                                            <span class="n">factr</span><span class="o">=</span><span class="n">factr</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="n">m</span><span class="p">,</span> <span class="n">maxls</span><span class="o">=</span><span class="n">maxls</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="n">maxiter</span><span class="p">)</span>
            <span class="n">l_bfgs_b_optimizer</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>

        <span class="c1"># Only used if using l_bfgs_b_optimizer = False
</span>        <span class="k">if</span> <span class="ow">not</span> <span class="n">use_l_bfgs_b_optimizer</span><span class="p">:</span>
            <span class="c1"># I use data_adapter.get_data_handler similar to the standard fit method
</span>            <span class="c1"># Create a data handler using the input data and provided parameters
</span>            <span class="n">data_handler</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="nf">get_data_handler</span><span class="p">(</span>
                                            <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
                                            <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
                                            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                                            <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
                                            <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
                                            <span class="n">model</span><span class="o">=</span><span class="n">self</span>
                                        <span class="p">)</span>
            <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="c1"># I use callbacks_module.CallbackList similar to the standard fit method
</span>            <span class="c1"># Create a callback list to manage the training process and display progress
</span>            <span class="n">callbacks</span> <span class="o">=</span> <span class="n">callbacks_module</span><span class="p">.</span><span class="nc">CallbackList</span><span class="p">(</span>
                            <span class="bp">None</span><span class="p">,</span>
                            <span class="n">add_history</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                            <span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span>
                            <span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span>
                            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                            <span class="n">epochs</span> <span class="o">=</span> <span class="n">epochs</span><span class="p">,</span>
                            <span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="p">.</span><span class="n">inferred_steps</span><span class="p">,</span>
                        <span class="p">)</span>
            
            <span class="n">callbacks</span><span class="p">.</span><span class="nf">on_train_begin</span><span class="p">()</span>
            <span class="c1"># data_handler.enumerate_epochs generate a iterator and epochs
</span>            <span class="k">for</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">data_iterator</span> <span class="ow">in</span> <span class="n">data_handler</span><span class="p">.</span><span class="nf">enumerate_epochs</span><span class="p">():</span>
                <span class="n">self</span><span class="p">.</span><span class="nf">reset_metrics</span><span class="p">()</span>  
                <span class="n">callbacks</span><span class="p">.</span><span class="nf">on_epoch_begin</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>  
                <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">data_handler</span><span class="p">.</span><span class="nf">steps</span><span class="p">():</span>            
                    <span class="n">callbacks</span><span class="p">.</span><span class="nf">on_train_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
                    <span class="c1"># Get the current batch of data from the data_iterator
</span>                    <span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span> <span class="o">=</span> <span class="nf">next</span><span class="p">(</span><span class="n">data_iterator</span><span class="p">)</span>
                    <span class="c1"># Perform one training step with the current batch of data
</span>                    <span class="n">logs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">train_step</span><span class="p">((</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">))</span>     
                    <span class="n">callbacks</span><span class="p">.</span><span class="nf">on_train_batch_end</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>   
                
                <span class="c1"># End the current epoch and update the logs             
</span>                <span class="n">callbacks</span><span class="p">.</span><span class="nf">on_epoch_end</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>
            <span class="n">callbacks</span><span class="p">.</span><span class="nf">on_train_end</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">callbacks</span><span class="p">.</span><span class="n">_history</span>
</code></pre></div></div>

<h1 id="main">Main</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n_train</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">n_test</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># Training Input Data Preparation -----------------------
# Initialize random points within the domain (x, t)
</span><span class="n">x</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">n_train</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>  <span class="c1"># x in [-1,1]
</span><span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">n_train</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>          <span class="c1"># t in [0, 1]
</span><span class="n">xt</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>     <span class="c1"># Combine x and t for training input
</span>
<span class="c1"># Initialize random points for initial condition: (x_0, t_0 = 0)
</span><span class="n">x_0</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">n_train</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>  <span class="c1"># x_0 in [-1,1]
</span><span class="n">t_0</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">n_train</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>              <span class="c1"># t_0 = 0
</span><span class="n">xt_0</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">((</span><span class="n">x_0</span><span class="p">,</span> <span class="n">t_0</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Combine x_0 and t_0 for initial condition input
</span>
<span class="c1"># Initialize random points for boundary conditions
</span><span class="n">t_bnd</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">n_train</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>        <span class="c1"># t in [0, 1]
</span><span class="n">x_bnd</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">round</span><span class="p">(</span><span class="n">t_bnd</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>           <span class="c1"># x is either -1 or 1
</span><span class="n">xt_bnd</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">((</span><span class="n">x_bnd</span><span class="p">,</span> <span class="n">t_bnd</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Combine x_bnd and t_bnd for boundary condition input
</span>
<span class="c1"># Training Output Data Preparation ---------------------
# Residuals: the model will try to minimize these to satisfy the PDE
</span><span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">n_train</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># Target residual values (ideal residuals)
</span>
<span class="c1"># Initial condition output
</span><span class="n">u_0</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">x_0</span><span class="p">)</span>               <span class="c1"># u(0, x)  = -sin(pi x)
</span>
<span class="c1"># Boundary condition output
</span><span class="n">u_bnd</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">n_train</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>           <span class="c1"># u(t, 1) = u(t, -1) = 0 for boundary points
</span>
<span class="c1"># Train the model ------------------------
</span><span class="n">x_train</span> <span class="o">=</span> <span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="n">xt_0</span><span class="p">,</span> <span class="n">xt_bnd</span><span class="p">)</span>             <span class="c1"># Input domain : (1000, 2)
</span><span class="n">y_train</span> <span class="o">=</span> <span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">u_0</span><span class="p">,</span> <span class="n">u_bnd</span><span class="p">)</span>                <span class="c1"># Output values: (1000, 1)
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dnn</span> <span class="o">=</span> <span class="nc">DNN</span><span class="p">()</span>
<span class="n">pinn</span> <span class="o">=</span> <span class="nc">PINN</span><span class="p">(</span><span class="n">dnn</span><span class="p">)</span>

<span class="n">pinn</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="nc">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">))</span>
<span class="c1">#pinn.fit(x_train, y_train, batch_size = 32, epochs = 100)
</span><span class="n">pinn</span><span class="p">.</span><span class="nf">custom_fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">use_l_bfgs_b_optimizer</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Optimizer: L-BFGS-B (maxiter=5000)
Epoch 1/5000
1/1 [==============================] - 0s 0s/step - loss: 0.1267
Epoch 1001/5000
1/1 [==============================] - 0s 0s/step - loss: 0.0021
Epoch 2001/5000
1/1 [==============================] - 0s 1ms/step - loss: 8.3402e-04
Epoch 3001/5000
1/1 [==============================] - 0s 1ms/step - loss: 2.2208e-04
Epoch 4001/5000
1/1 [==============================] - 0s 1ms/step - loss: 6.1321e-05
</code></pre></div></div>

<h1 id="plots">Plots</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># predict u(t,x) distribution
</span><span class="n">t_flat</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_test</span><span class="p">)</span>
<span class="n">x_flat</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_test</span><span class="p">)</span>
<span class="n">x</span><span class="p">,</span><span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">meshgrid</span><span class="p">(</span><span class="n">x_flat</span><span class="p">,</span> <span class="n">t_flat</span><span class="p">)</span>
<span class="n">xt</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">x</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(),</span> <span class="n">t</span><span class="p">.</span><span class="nf">flatten</span><span class="p">()],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">dnn</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">n_test</span><span class="p">)</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">u</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">t</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># plot u(t,x) distribution as a color-map
</span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">gs</span> <span class="o">=</span> <span class="nc">GridSpec</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">pcolormesh</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">RdBu</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">t</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">)</span>
<span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">colorbar</span><span class="p">(</span><span class="n">pad</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">cbar</span><span class="p">.</span><span class="nf">set_label</span><span class="p">(</span><span class="sh">'</span><span class="s">u(t,x)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">cbar</span><span class="p">.</span><span class="n">mappable</span><span class="p">.</span><span class="nf">set_clim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># plot u(t=const, x) cross-sections
</span><span class="n">t_cross_sections</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">t_cs</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">t_cross_sections</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">])</span>
    <span class="n">xt</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">x_flat</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">full</span><span class="p">(</span><span class="n">t_flat</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">t_cs</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">dnn</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">n_test</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x_flat</span><span class="p">,</span> <span class="n">u</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">t={}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">t_cs</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">u(t,x)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100/100 [==============================] - 0s 509us/step
1/1 [==============================] - 0s 10ms/step
1/1 [==============================] - 0s 11ms/step
1/1 [==============================] - 0s 13ms/step
</code></pre></div></div>

<center>
<img src="/assets/img/post7/2d_plot_burger.png" width="700" height="400" />
</center>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># plot u(t,x) distribution as a 3D plot
</span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="nf">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="sh">'</span><span class="s">3d</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Plot the surface
</span><span class="n">surf</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="nf">plot_surface</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">RdBu</span><span class="sh">'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">antialiased</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Customize the plot
</span><span class="n">ax</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">t</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_zlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">u(x,t)</span><span class="sh">'</span><span class="p">)</span>
<span class="c1"># Rotate the plot
</span><span class="n">elevation_angle</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="n">elev</span>  <span class="c1"># keep the same elevation angle
</span><span class="n">azimuthal_angle</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="n">azim</span> <span class="o">+</span> <span class="mi">160</span>  <span class="c1"># change the azimuthal angle by 90 degrees
</span><span class="n">ax</span><span class="p">.</span><span class="nf">view_init</span><span class="p">(</span><span class="n">elevation_angle</span><span class="p">,</span> <span class="n">azimuthal_angle</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">colorbar</span><span class="p">(</span><span class="n">surf</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<center>
<img src="/assets/img/post7/3d_plot_burger.png" width="700" height="400" />
</center>



  
    
<div id="disqus_thread"></div>
<script>
    /**
    *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
    *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables    */
    /*
    var disqus_config = function () {
    this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://https-marcosbenicio-github-io-1.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>



</div>


    </div>

  </body>
</html>
