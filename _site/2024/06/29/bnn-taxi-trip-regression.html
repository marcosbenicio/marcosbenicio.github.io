<!DOCTYPE html>




<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <meta property="og:image" content="/assets/img/post6/2head-bnn.png"/>
    
    
    <link rel="stylesheet" type="text/css" href="/assets/css/syntax_highlight.css">
    <link rel="stylesheet" type="text/css" href="/assets/css/main.css">
    <link rel="alternate" type="application/rss+xml" title="RSS Feed" href="atom.xml" />

    <!-- MathJax Configuration -->
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true
          }
        });
    </script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

    <script>
      function show_tag_section(tag) {
        // Hide all other tag divs
        document.getElementById('all_posts').style.display = 'none';
        var tag_divs = document.getElementsByClassName('by_tag');
        var i;
        for (var i = 0; i < tag_divs.length; i++) {
          tag_divs[i].style.display = 'none';
        }
        // Show the one we want
        document.getElementById(tag).style.display = 'block';
      }
    </script>
    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico">
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Uncertainty Estimation for Taxi Trip Duration Predictions in NYC | Marcos Benício</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="Uncertainty Estimation for Taxi Trip Duration Predictions in NYC" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="This project aims to analyze taxi trip durations in NYC for the year 2023. The dataset contains almost 35 million records. We perform brief preprocessing to remove outliers and errors, using DuckDB and SQL to extract 2 million representative records. After preprocessing, we use this data to train three models: a simple neural network without uncertainty estimation, a Bayesian neural network (BNN), and a dual-headed Bayesian neural network (Dual BNN). We compare these models, highlighting that the Dual BNN can vary its uncertainty estimates based on the input data, unlike the simple BNN which estimates a constant level of uncertainty, and the simple neural network which provides only point estimates. The Dual BNN’s ability to provide varying uncertainty estimates makes it particularly advantageous for predicting taxi trip durations, as it offers more informative and reliable predictions, crucial for effective decision-making in real-world applications." />
<meta property="og:description" content="This project aims to analyze taxi trip durations in NYC for the year 2023. The dataset contains almost 35 million records. We perform brief preprocessing to remove outliers and errors, using DuckDB and SQL to extract 2 million representative records. After preprocessing, we use this data to train three models: a simple neural network without uncertainty estimation, a Bayesian neural network (BNN), and a dual-headed Bayesian neural network (Dual BNN). We compare these models, highlighting that the Dual BNN can vary its uncertainty estimates based on the input data, unlike the simple BNN which estimates a constant level of uncertainty, and the simple neural network which provides only point estimates. The Dual BNN’s ability to provide varying uncertainty estimates makes it particularly advantageous for predicting taxi trip durations, as it offers more informative and reliable predictions, crucial for effective decision-making in real-world applications." />
<link rel="canonical" href="http://localhost:4000/2024/06/29/bnn-taxi-trip-regression.html" />
<meta property="og:url" content="http://localhost:4000/2024/06/29/bnn-taxi-trip-regression.html" />
<meta property="og:site_name" content="Marcos Benício" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-06-29T00:00:00-03:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Uncertainty Estimation for Taxi Trip Duration Predictions in NYC" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2024-06-29T00:00:00-03:00","datePublished":"2024-06-29T00:00:00-03:00","description":"This project aims to analyze taxi trip durations in NYC for the year 2023. The dataset contains almost 35 million records. We perform brief preprocessing to remove outliers and errors, using DuckDB and SQL to extract 2 million representative records. After preprocessing, we use this data to train three models: a simple neural network without uncertainty estimation, a Bayesian neural network (BNN), and a dual-headed Bayesian neural network (Dual BNN). We compare these models, highlighting that the Dual BNN can vary its uncertainty estimates based on the input data, unlike the simple BNN which estimates a constant level of uncertainty, and the simple neural network which provides only point estimates. The Dual BNN’s ability to provide varying uncertainty estimates makes it particularly advantageous for predicting taxi trip durations, as it offers more informative and reliable predictions, crucial for effective decision-making in real-world applications.","headline":"Uncertainty Estimation for Taxi Trip Duration Predictions in NYC","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2024/06/29/bnn-taxi-trip-regression.html"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/img/profile_photo.png"}},"url":"http://localhost:4000/2024/06/29/bnn-taxi-trip-regression.html"}</script>
<!-- End Jekyll SEO tag -->

  </head>
  <body onload="show_tag_section('all_posts')">

    <div class="header">

      <!-- Large header banner on left for large display widths -->
      <div class="big_header">

        <!-- Name -->
        <div class="name_group">
          <h1><a href="/">Marcos Benício</a></h1>
        </div>

        <!-- <a href=""><img src="/assets/img/profile_photo.png" alt="Logo" class="center_img" ></a>-->
        <a href="/"><img src="/assets/img/profile_photo.png" alt="Logo" class="center_img" ></a>
        <!--<a href=""><img src="/assets/img/profile_photo.png" alt="Logo" class="center_img" ></a>-->



        <!-- Position + company -->
        <div class="link_group">

          <div class="row">
              <div class="col1">
                <span> M.sc in Physics</span>
              </div>
          </div>

          <div class="row">
            <!-- <a href=""-->
              <div class="col1">
                <img src="/assets/img/brazil_icon.png" height="30" width="30">
                <!-- <span>  </span>-->
              </div>
            </a>
          </div>

          <div class="row">
            <div class="col1">
              <img src="/assets/img/place_icon_light.png" height="16" width="16">
              <span> Niterói, RJ </span>
            </div>
          </div>

        </div>

        <!-- Badges/links -->
        <div class="link_group">

          <div class="row">
            <a href="https://github.com/marcosbenicio">
              <div class="col2">
                <img src="/assets/img/github_icon_light.png" height="16" width="16">
                <span> Github </span>
              </div>
            </a>
            <a href="https://linkedin.com/in/marcos-benício-de-andrade-alonso-415a5b16b">
              <div class="col2">
                <img src="/assets/img/linkedin_icon_light.png" height="16" width="16">
                <span> LinkedIn </span>
              </div>
            </a>
          </div>

          <div class="row">
            <a href="mailto:marcosbenicio0102@gmail.com">
              <div class="col2">
                <img src="/assets/img/email_icon_light.png" height="16" width="16">
                <span> Email </span>
              </div>
            </a>
            <a href="/assets/files/resume.pdf">
              <div class="col2">
                <img src="/assets/img/cv_icon_light.png" height="16" width="16">
                <span> Resume </span>
              </div>
            </a>
          </div>

        </div>

      </div>

      <!-- Smaller header banner on top for small display widths -->
      <div class="small_header">

        <!-- Name -->
        <div class="small_header_box">
          <div class="name_header_box">
            <div class="name_header_img">
              <a href="/">
                <img src="/assets/img/profile_photo.png" alt="Logo" height="60">
              </a>
            </div>
            <div class="name_header_name">
              <h1><a href="/">Marcos Benício</a></h1>
            </div>
          </div>
        </div>

        <!-- Position + Company -->
        <div class="small_header_box">
          <div class="row">
            <div class="col1">
              <span> M.sc in Physics </span>
            </div>
          </div>
          <div class="row">
            <div class="col1">
             <!-- <a href=""> -->
                  <img src="/assets/img/brazil_icon.png" height="30" width="30">
                  <!-- <span>  </span> -->
              </a>
            </div>
          </div>
        </div>

        <!-- Badges/links -->
        <div class="small_header_box">
                <div class="row">
                  <a href="https://github.com/marcosbenicio">
                    <div class="col2">
                      <img src="/assets/img/github_icon_light.png" height="16" width="16">
                      <span> Github </span>
                    </div>
                  </a>
                  <a href="https://linkedin.com/in/marcos-benício-de-andrade-alonso-415a5b16b">
                    <div class="col2">
                      <img src="/assets/img/linkedin_icon_light.png" height="16" width="16">
                      <span> LinkedIn </span>
                    </div>
                  </a>
                </div>

                <div class="row">
                  <a href="mailto:marcosbenicio0102@gmail.com">
                    <div class="col2">
                      <img src="/assets/img/email_icon_light.png" height="16" width="16">
                      <span> Email </span>
                    </div>
                  </a>
                  <a href="/assets/files/resume.pdf">
                    <div class="col2">
                      <img src="/assets/img/cv_icon_light.png" height="16" width="16">
                      <span> Resume </span>
                    </div>
                  </a>
                </div>
        </div>

      </div>

    </div>

    <!-- Page content -->
    <div class="content">

      <h1>Uncertainty Estimation for Taxi Trip Duration Predictions in NYC</h1>
<p class="meta">29 Jun 2024 - Tags: Multilayer Perceptron, Bayesian Neural Network, and Regression</p>

<div class="button_container">
  
    <a href="https://github.com/marcosbenicio/bayesian-neural-network/blob/main/02-regression/bnn-regression.ipynb">
      <div class="button_link">
        View on<br /><strong>Github</strong>
      </div>
    </a>
  
  
  
</div>


<div class="post">
  <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">geopandas</span> <span class="k">as</span> <span class="n">gpd</span>
<span class="kn">from</span> <span class="n">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="kn">import</span> <span class="n">sklearn</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="kn">import</span> <span class="n">duckdb</span>
<span class="kn">from</span> <span class="n">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>
<span class="kn">from</span> <span class="n">scipy.stats</span> <span class="kn">import</span> <span class="n">gaussian_kde</span>
<span class="kn">from</span> <span class="n">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span>
<span class="kn">from</span> <span class="n">scipy.stats</span> <span class="kn">import</span> <span class="n">multivariate_normal</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="n">keras.models</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="n">keras.layers</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Layer</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">BatchNormalization</span><span class="p">,</span> <span class="n">LeakyReLU</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">,</span> <span class="n">ReLU</span>

<span class="kn">from</span> <span class="n">keras.losses</span> <span class="kn">import</span> <span class="n">Loss</span><span class="p">,</span> <span class="n">mse</span><span class="p">,</span> <span class="n">MeanSquaredError</span>
<span class="kn">from</span> <span class="n">keras.optimizers</span> <span class="kn">import</span> <span class="n">Optimizer</span><span class="p">,</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="n">keras.regularizers</span> <span class="kn">import</span> <span class="n">L2</span>
<span class="kn">from</span> <span class="n">keras.metrics</span> <span class="kn">import</span> <span class="n">Mean</span><span class="p">,</span> <span class="n">MeanAbsoluteError</span>
<span class="kn">from</span> <span class="n">keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span><span class="p">,</span> <span class="n">plot_model</span><span class="p">,</span> <span class="n">load_img</span><span class="p">,</span> <span class="n">img_to_array</span>
<span class="kn">from</span> <span class="n">keras.callbacks</span> <span class="kn">import</span> <span class="n">EarlyStopping</span>
<span class="kn">from</span> <span class="n">keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">make_scorer</span><span class="p">,</span> <span class="n">mean_squared_error</span>

<span class="kn">from</span> <span class="n">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyRegressor</span>

<span class="kn">import</span> <span class="n">tensorflow_probability</span> <span class="k">as</span> <span class="n">tfp</span>
<span class="kn">from</span> <span class="n">tensorflow_probability</span> <span class="kn">import</span> <span class="n">distributions</span> <span class="k">as</span> <span class="n">tfd</span>

<span class="c1"># Geospatial 
</span><span class="kn">from</span> <span class="n">geopy</span> <span class="kn">import</span> <span class="n">distance</span>
<span class="kn">import</span> <span class="n">geopandas</span> <span class="k">as</span> <span class="n">gpd</span>
<span class="kn">import</span> <span class="n">pickle</span>

<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</code></pre></div></div>

<h1 id="outline">Outline</h1>

<ul>
  <li><a href="#data-preparation"><strong>Data Preparation</strong></a>
    <ul>
      <li><a href="#handling-some-outliers"><strong>Handling Some Outliers</strong></a></li>
    </ul>
  </li>
  <li><a href="#simple-neural-network"><strong>Simple Neural Network</strong></a></li>
  <li><a href="#simple-neural-network"><strong>Simple Bayesian Neural Network</strong></a></li>
  <li><a href="#two-heads-bayesian-neural-network"><strong>Two Heads Bayesian Neural Network</strong></a></li>
  <li><a href="#conclusion"><strong>Conclusion</strong></a>
    <ul>
      <li><a href="#learning-curves">Learning Curves</a></li>
      <li><a href="#residuals">Residuals</a></li>
      <li><a href="#predictive-distributions">Predictive Distributions</a></li>
    </ul>
  </li>
</ul>

<h1 id="data-preparation"><strong>Data Preparation</strong></h1>

<p>We gonna use a bash script to automate the download of data from <a href="https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page">NYC Trip Record Data</a> for yellow taxi trips in the year 2023. The bash script is the following:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Shell exit immediately if a command exits with a error</span>
<span class="nb">set</span> <span class="nt">-e</span>

<span class="c"># Args to pass when running the script</span>
<span class="c"># Usage: ./download_data.sh {1} {2}</span>
<span class="nv">TAXI_TYPE</span><span class="o">=</span><span class="nv">$1</span>  <span class="c"># First argument: Taxi type ("yellow" or "green")</span>
<span class="nv">YEAR</span><span class="o">=</span><span class="nv">$2</span>       <span class="c"># Second argument: Year (e.g., 2022 or 2023)</span>
<span class="nv">URL_PREFIX</span><span class="o">=</span><span class="s2">"https://d37ci6vzurychx.cloudfront.net/trip-data"</span>

<span class="c"># Loop through all months of the year</span>
<span class="k">for </span>MONTH <span class="k">in</span> <span class="o">{</span>1..12<span class="o">}</span><span class="p">;</span> <span class="k">do</span>
  <span class="c"># Format integers to have 2 digits for month (e.g., 01, 02)</span>
  <span class="nv">FMONTH</span><span class="o">=</span><span class="sb">`</span><span class="nb">printf</span> <span class="s2">"%02d"</span> <span class="k">${</span><span class="nv">MONTH</span><span class="k">}</span><span class="sb">`</span>
  <span class="c"># Construct URL for the monthly data file</span>
  <span class="nv">URL</span><span class="o">=</span><span class="s2">"</span><span class="k">${</span><span class="nv">URL_PREFIX</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">TAXI_TYPE</span><span class="k">}</span><span class="s2">_tripdata_</span><span class="k">${</span><span class="nv">YEAR</span><span class="k">}</span><span class="s2">-</span><span class="k">${</span><span class="nv">FMONTH</span><span class="k">}</span><span class="s2">.parquet"</span>

  <span class="c"># Define local storage path structure</span>
  <span class="nv">LOCAL_PREFIX</span><span class="o">=</span><span class="s2">"data/raw/</span><span class="k">${</span><span class="nv">TAXI_TYPE</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">YEAR</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">FMONTH</span><span class="k">}</span><span class="s2">"</span>
  <span class="nv">LOCAL_FILE</span><span class="o">=</span><span class="s2">"</span><span class="k">${</span><span class="nv">TAXI_TYPE</span><span class="k">}</span><span class="s2">_tripdata_</span><span class="k">${</span><span class="nv">YEAR</span><span class="k">}</span><span class="s2">_</span><span class="k">${</span><span class="nv">FMONTH</span><span class="k">}</span><span class="s2">.parquet"</span>
  <span class="nv">LOCAL_PATH</span><span class="o">=</span><span class="s2">"</span><span class="k">${</span><span class="nv">LOCAL_PREFIX</span><span class="k">}</span><span class="s2">/</span><span class="k">${</span><span class="nv">LOCAL_FILE</span><span class="k">}</span><span class="s2">"</span>

  <span class="c"># Output the download process</span>
  <span class="nb">echo</span> <span class="s2">"downloading </span><span class="k">${</span><span class="nv">URL</span><span class="k">}</span><span class="s2"> to </span><span class="k">${</span><span class="nv">LOCAL_PATH</span><span class="k">}</span><span class="s2">"</span>
  <span class="c"># Create the specified directory and any parent directories as needed</span>
  <span class="nb">mkdir</span> <span class="nt">-p</span> <span class="k">${</span><span class="nv">LOCAL_PREFIX</span><span class="k">}</span>

  <span class="c"># Download the file from the URL to the specified local path</span>
  wget <span class="k">${</span><span class="nv">URL</span><span class="k">}</span> <span class="nt">-O</span> <span class="k">${</span><span class="nv">LOCAL_PATH</span><span class="k">}</span>

<span class="k">done</span>

</code></pre></div></div>

<p>Save this script file as <code class="language-plaintext highlighter-rouge">donwload_data.sh</code>. The script will create the folder <code class="language-plaintext highlighter-rouge">data/raw/TAXI_TYPE/YEAR/MONTH</code>, and in each month folder will contain a parquet file for taxi trips in NYC. Before running the script, we must make it executable:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">chmod</span> +x download_data.sh
</code></pre></div></div>

<p>The script requires two parameters: the taxi type (yellow or green) and the year. To run the script we use the following command:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./download_data.sh yellow 2023
</code></pre></div></div>

<p>We should see a three directory like the following by typing <code class="language-plaintext highlighter-rouge">tree data</code> (is necessary to install tree command: <code class="language-plaintext highlighter-rouge">sudo apt-get install tree</code>):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>data
├── raw
│   └── yellow
│       ├── 2023
│       │   ├── 01
│       │   │   └── yellow_tripdata_2023_01.parquet
│       │   ├── 02
│       │   │   └── yellow_tripdata_2023_02.parquet
│       │   ├── 03
│       │   │   └── yellow_tripdata_2023_03.parquet
│       │   ├── 04
│       │   │   └── yellow_tripdata_2023_04.parquet
│       │   ├── 05
│       │   │   └── yellow_tripdata_2023_05.parquet
│       │   ├── 06
│       │   │   └── yellow_tripdata_2023_06.parquet
│       │   ├── 07
│       │   │   └── yellow_tripdata_2023_07.parquet
│       │   ├── 08
│       │   │   └── yellow_tripdata_2023_08.parquet
│       │   ├── 09
│       │   │   └── yellow_tripdata_2023_09.parquet
│       │   ├── 10
│       │   │   └── yellow_tripdata_2023_10.parquet
│       │   ├── 11
│       │   │   └── yellow_tripdata_2023_11.parquet
│       │   ├── 12
│       │   │   └── yellow_tripdata_2023_12.parquet
</code></pre></div></div>

<p>Another necessary dataset with the locations of each taxi pickup and dropoff is the <a href="https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv">Taxi Zone Lookup</a> and the <a href="https://d37ci6vzurychx.cloudfront.net/misc/taxi_zones.zip">Taxi Zone Shapefile</a> with the coordinates in feet. Create the folder <code class="language-plaintext highlighter-rouge">data/external</code> and download both data.</p>

<p>Now let’s create a dataset for the taxi zone lookup with the necessary features from the shapefile using geopandas. The shape file contains information about the coordinates in feet and the taxi zone lookup the id for each zone in NYC. The final dataset will have `Zone’, ‘longitude’ and ‘latitude’ as the relevant features to be used, where the longitude and latitude is the centroid location for each zone from NYC map.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_taxi_zones</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">data/external/taxi_zone_lookup.csv</span><span class="sh">'</span><span class="p">)</span> 
<span class="n">df_taxi_zones</span> <span class="o">=</span> <span class="n">df_taxi_zones</span><span class="p">.</span><span class="nf">dropna</span><span class="p">()</span>

<span class="c1"># Load the spatial data
</span><span class="n">gdf_zones</span> <span class="o">=</span> <span class="n">gpd</span><span class="p">.</span><span class="nf">read_file</span><span class="p">(</span><span class="sh">'</span><span class="s">data/external/nyc-taxi-zones/taxi_zones.shp</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Ensure the spatial data has a column that matches the DataFrame `LocationID` or `Zone`
# Let's assume the matching column in gdf_zones is 'zone_name'
</span><span class="n">gdf_zones</span> <span class="o">=</span> <span class="n">gdf_zones</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">zone</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">Zone</span><span class="sh">'</span><span class="p">})</span>

<span class="c1"># Compute centroids
</span><span class="n">gdf_zones</span><span class="p">[</span><span class="sh">'</span><span class="s">centroid</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">gdf_zones</span><span class="p">.</span><span class="n">geometry</span><span class="p">.</span><span class="n">centroid</span>

<span class="c1"># Extract longitude and latitude from the centroids
</span><span class="n">gdf_zones</span><span class="p">[</span><span class="sh">'</span><span class="s">longitude</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">gdf_zones</span><span class="p">.</span><span class="n">centroid</span><span class="p">.</span><span class="n">x</span>
<span class="n">gdf_zones</span><span class="p">[</span><span class="sh">'</span><span class="s">latitude</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">gdf_zones</span><span class="p">.</span><span class="n">centroid</span><span class="p">.</span><span class="n">y</span>

<span class="c1"># Merge this back into your original DataFrame
</span><span class="n">df_taxi_zones</span> <span class="o">=</span> <span class="n">df_taxi_zones</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">gdf_zones</span><span class="p">[[</span><span class="sh">'</span><span class="s">Zone</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">longitude</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">latitude</span><span class="sh">'</span><span class="p">]],</span> <span class="n">on</span><span class="o">=</span><span class="sh">'</span><span class="s">Zone</span><span class="sh">'</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">)</span>

<span class="n">df_taxi_zones</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">"</span><span class="s">data/external/taxi_zone_lookup_feet.csv</span><span class="sh">"</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="nf">display</span><span class="p">(</span><span class="n">df_taxi_zones</span><span class="p">.</span><span class="nf">head</span><span class="p">())</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>LocationID</th>
      <th>Borough</th>
      <th>Zone</th>
      <th>service_zone</th>
      <th>longitude</th>
      <th>latitude</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>EWR</td>
      <td>Newark Airport</td>
      <td>EWR</td>
      <td>9.359968e+05</td>
      <td>191376.749531</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>Queens</td>
      <td>Jamaica Bay</td>
      <td>Boro Zone</td>
      <td>1.031086e+06</td>
      <td>164018.754403</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>Bronx</td>
      <td>Allerton/Pelham Gardens</td>
      <td>Boro Zone</td>
      <td>1.026453e+06</td>
      <td>254265.478659</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Manhattan</td>
      <td>Alphabet City</td>
      <td>Yellow Zone</td>
      <td>9.906340e+05</td>
      <td>202959.782391</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Staten Island</td>
      <td>Arden Heights</td>
      <td>Boro Zone</td>
      <td>9.318714e+05</td>
      <td>140681.351376</td>
    </tr>
  </tbody>
</table>
</div>

<p>Now we can focus on the yellow taxi dataset, that contains almost 34933659 records for the year 2023. Because we have a very large number of records, instead of loading the data into pandas, I choose to use <code class="language-plaintext highlighter-rouge">duckdb</code> to handle the data by using SQL.</p>

<p>We first create a database connection inside the folder <code class="language-plaintext highlighter-rouge">data/taxi_data.duckdb</code> and then create the necessary schema for the yellow taxi trip table. Then read each parquet file inside the month folders to create a single table with all the data from each month and another table with latitude and longitude from <code class="language-plaintext highlighter-rouge">taxi_zone_lookup_feet.csv</code> that was created. The result should be a table containing 34933659 records named <code class="language-plaintext highlighter-rouge">yellow_taxi_2023_full</code> and a table <code class="language-plaintext highlighter-rouge">taxi_zone_lookup_coord</code> for the coordinate zones in foots.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Connect to DuckDB
</span><span class="n">conn</span> <span class="o">=</span> <span class="n">duckdb</span><span class="p">.</span><span class="nf">connect</span><span class="p">(</span><span class="n">database</span><span class="o">=</span><span class="sa">f</span><span class="sh">"</span><span class="s">data/taxi_data.duckdb</span><span class="sh">"</span><span class="p">,</span> <span class="n">read_only</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># Define a schema for the table for parquet file
</span><span class="n">conn</span><span class="p">.</span><span class="nf">sql</span><span class="p">(</span><span class="sh">"""</span><span class="s">
CREATE OR REPLACE TABLE yellow_taxi_2023_full (
VendorID INTEGER,         
tpep_pickup_datetime TIMESTAMP,
tpep_dropoff_datetime TIMESTAMP,
passenger_count FLOAT,       
trip_distance FLOAT,       
RatecodeID FLOAT,       
store_and_fwd_flag TEXT,        
PULocationID INTEGER,         
DOLocationID INTEGER,         
payment_type INTEGER,         
fare_amount FLOAT,       
extra FLOAT,       
mta_tax FLOAT,       
tip_amount FLOAT,       
tolls_amount FLOAT,       
improvement_surcharge FLOAT,       
total_amount FLOAT,       
congestion_surcharge FLOAT,       
airport_fee FLOAT 
);
</span><span class="sh">"""</span><span class="p">)</span>

<span class="c1"># table for geographical coordinates
</span><span class="n">conn</span><span class="p">.</span><span class="nf">sql</span><span class="p">(</span>
<span class="sh">"""</span><span class="s"> 
CREATE OR REPLACE TABLE taxi_zone_lookup_coord AS
    SELECT 
        LocationID,
        latitude,	
        longitude,
    FROM read_csv_auto(</span><span class="sh">'</span><span class="s">data/external/taxi_zone_lookup_feet.csv</span><span class="sh">'</span><span class="s">)
</span><span class="sh">"""</span>
<span class="p">)</span>

<span class="n">root_dir</span> <span class="o">=</span> <span class="sh">"</span><span class="s">data/raw/yellow/2023</span><span class="sh">"</span>
<span class="c1"># Insert data directly into a DuckDB table from `.parquet` files
</span><span class="k">for</span> <span class="n">month</span> <span class="ow">in</span> <span class="nf">sorted</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="nf">listdir</span><span class="p">(</span><span class="n">root_dir</span><span class="p">)):</span>
    <span class="n">month_path</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">root_dir</span><span class="p">,</span> <span class="n">month</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">isdir</span><span class="p">(</span><span class="n">month_path</span><span class="p">):</span>
        <span class="k">for</span> <span class="nb">file</span> <span class="ow">in</span> <span class="n">os</span><span class="p">.</span><span class="nf">listdir</span><span class="p">(</span><span class="n">month_path</span><span class="p">):</span>
            <span class="c1"># concatenates the directory path with file name
</span>            <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">month_path</span><span class="p">,</span> <span class="nb">file</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">file</span><span class="p">.</span><span class="nf">endswith</span><span class="p">(</span><span class="sh">"</span><span class="s">.parquet</span><span class="sh">"</span><span class="p">):</span>
                <span class="c1"># Using DuckDB SQL to read `.parquet` directly into a table
</span>                <span class="n">conn</span><span class="p">.</span><span class="nf">sql</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
                    COPY yellow_taxi_2023_full 
                    FROM </span><span class="sh">'</span><span class="si">{</span><span class="n">file_path</span><span class="si">}</span><span class="sh">'</span><span class="s"> (FORMAT </span><span class="sh">'</span><span class="s">PARQUET</span><span class="sh">'</span><span class="s">);
                </span><span class="sh">"""</span><span class="p">)</span>
<span class="n">conn</span><span class="p">.</span><span class="nf">sql</span><span class="p">(</span>
<span class="sh">"""</span><span class="s">
SELECT COUNT(*) AS yellow_taxi_2023_count
FROM yellow_taxi_2023_full
</span><span class="sh">"""</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    ┌────────────────────────┐
    │ yellow_taxi_2023_count │
    │         int64          │
    ├────────────────────────┤
    │               38310226 │
    └────────────────────────┘
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">conn</span><span class="p">.</span><span class="nf">sql</span><span class="p">(</span>
<span class="sh">"""</span><span class="s">
SHOW TABLES
</span><span class="sh">"""</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    ┌────────────────────────┐
    │          name          │
    │        varchar         │
    ├────────────────────────┤
    │ taxi_zone_lookup_coord │
    │ yellow_taxi_2023       │
    │ yellow_taxi_2023_full  │
    └────────────────────────┘
</code></pre></div></div>

<p>We can see that the number of instances for each month is balanced but there is some outliers, probably inserted by mistake that needs to be removed. We can see trips for years like, for example, 2021, 2002, 2003 that don’t make sense, given that the dataset contains only data from 2023:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">conn</span><span class="p">.</span><span class="nf">sql</span><span class="p">(</span>
<span class="sh">"""</span><span class="s">
SELECT
    strftime(</span><span class="sh">'</span><span class="s">%Y-%m</span><span class="sh">'</span><span class="s">, tpep_pickup_datetime) AS month,
    COUNT(*) AS count
FROM yellow_taxi_2023_full
GROUP BY month
ORDER BY month
</span><span class="sh">"""</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    ┌─────────┬─────────┐
    │  month  │  count  │
    │ varchar │  int64  │
    ├─────────┼─────────┤
    │ 2001-01 │       6 │
    │ 2002-12 │      11 │
    │ 2003-01 │       6 │
    │ 2008-12 │      23 │
    │ 2009-01 │      15 │
    │ 2014-11 │       1 │
    │ 2022-10 │      11 │
    │ 2022-12 │      25 │
    │ 2023-01 │ 3066726 │
    │ 2023-02 │ 2914003 │
    │ 2023-03 │ 3403660 │
    │ 2023-04 │ 3288248 │
    │ 2023-05 │ 3513664 │
    │ 2023-06 │ 3307259 │
    │ 2023-07 │ 2907093 │
    │ 2023-08 │ 2824201 │
    │ 2023-09 │ 2846741 │
    │ 2023-10 │ 3522269 │
    │ 2023-11 │ 3339731 │
    │ 2023-12 │ 3376527 │
    │ 2024-01 │       6 │
    ├─────────┴─────────┤
    │      21 rows      │
    └───────────────────┘
</code></pre></div></div>

<p>Let’s create a new <code class="language-plaintext highlighter-rouge">yellow_taxi_2023</code> table by selecting a random sample of 1.5 million records from the 2023 dataset, which contains more than 34.9 million records. Since the monthly data is balanced, random sampling ensures that the statistical characteristics of the entire dataset are preserved.</p>

<p>To add the geographic coordinates for the dropoff and pickup locations, we use the <code class="language-plaintext highlighter-rouge">taxi_zone_lookup_coord</code> table for the <code class="language-plaintext highlighter-rouge">PULocationID</code> and <code class="language-plaintext highlighter-rouge">DOLocationID</code> with an inner join. This join allows us to append the exact latitude and longitude for both the pickup and dropoff locations.</p>

<p>Finally, we filter the records to include only those from 2023, removing any potential outliers, and save the resulting table as a CSV file in the <code class="language-plaintext highlighter-rouge">data/raw/yellow/taxi_2023_raw.csv</code> folder.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">conn</span><span class="p">.</span><span class="nf">sql</span><span class="p">(</span>
<span class="sh">"""</span><span class="s">
CREATE OR REPLACE TABLE yellow_taxi_2023 AS
SELECT
    yt2023.tpep_pickup_datetime AS pickup_datetime,
    yt2023.tpep_dropoff_datetime AS dropoff_datetime,
    pickup_zone.latitude AS pickup_latitude,
    pickup_zone.longitude AS pickup_longitude,
    dropoff_zone.latitude AS dropoff_latitude,
    dropoff_zone.longitude AS dropoff_longitude
FROM 
    (SELECT 
        tpep_pickup_datetime,
        tpep_dropoff_datetime, 
        PULocationID,
        DOLocationID,
        strftime(</span><span class="sh">'</span><span class="s">%Y-%m</span><span class="sh">'</span><span class="s">, tpep_pickup_datetime) AS month
    FROM yellow_taxi_2023_full
    WHERE strftime(</span><span class="sh">'</span><span class="s">%Y</span><span class="sh">'</span><span class="s">, tpep_pickup_datetime) = </span><span class="sh">'</span><span class="s">2023</span><span class="sh">'</span><span class="s">
    ORDER BY RANDOM()
    LIMIT 2000000) AS yt2023
INNER JOIN 
    taxi_zone_lookup_coord AS pickup_zone
        ON pickup_zone.LocationID = yt2023.PULocationID
INNER JOIN 
    taxi_zone_lookup_coord AS dropoff_zone
        ON dropoff_zone.LocationID = yt2023.DOLocationID;
</span><span class="sh">"""</span>
<span class="p">)</span>

<span class="c1"># Save the result table as csv file
</span><span class="n">conn</span><span class="p">.</span><span class="nf">sql</span><span class="p">(</span>
<span class="sh">"""</span><span class="s">
SELECT * 
FROM yellow_taxi_2023
</span><span class="sh">"""</span><span class="p">).</span><span class="nf">df</span><span class="p">().</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">data/raw/yellow/taxi_2023_raw.csv</span><span class="sh">'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="feature-engineering">Feature Engineering</h2>

<p>Now that we have the dataset with just 1.5 million records and the correct pickup and dropoff coordinates for the NYC zones, it is time to create some useful features to train our neural networks.</p>

<p>First, we preprocess the datetime columns to create the <code class="language-plaintext highlighter-rouge">min_of_day</code>, <code class="language-plaintext highlighter-rouge">day_of_week</code>, <code class="language-plaintext highlighter-rouge">day_of_year</code> and <code class="language-plaintext highlighter-rouge">trip_duration</code> features. The <code class="language-plaintext highlighter-rouge">trip_duration</code> will be the target variables that we aim to predict in the regression model using a simple Neural Network and a Bayesian Neural Network. The other features are the dependent variables used as input for the models. After creating these features, we remove the original datetime columns, as they are no longer needed for training the neural network</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_taxi</span><span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">data/raw/yellow/taxi_2023_raw.csv</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#convert to datetime for easier manipulation
</span><span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">pickup_datetime</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">pickup_datetime</span><span class="sh">'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="nf">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
<span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">pickup_datetime</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span> <span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">pickup_datetime</span><span class="sh">'</span><span class="p">],</span> 
                                            <span class="n">utc</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="nb">format</span> <span class="o">=</span> <span class="sh">'</span><span class="s">%Y-%m-%d %H:%M</span><span class="sh">'</span><span class="p">)</span>

<span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">dropoff_datetime</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">dropoff_datetime</span><span class="sh">'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="nf">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
<span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">dropoff_datetime</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span> <span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">dropoff_datetime</span><span class="sh">'</span><span class="p">],</span> 
                                             <span class="n">utc</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="nb">format</span> <span class="o">=</span> <span class="sh">'</span><span class="s">%Y-%m-%d %H:%M</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Minutes in  a day : 0-1440
</span><span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">min_of_day</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">60</span><span class="o">*</span><span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">pickup_datetime</span><span class="sh">'</span><span class="p">].</span><span class="n">dt</span><span class="p">.</span><span class="n">hour</span> <span class="o">+</span> <span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">pickup_datetime</span><span class="sh">'</span><span class="p">].</span><span class="n">dt</span><span class="p">.</span><span class="n">minute</span><span class="p">)</span>
<span class="c1"># Days in a week: 0-6, where 0 is Monday and 6 Sunday
</span><span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">day_of_week</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">pickup_datetime</span><span class="sh">'</span><span class="p">].</span><span class="n">dt</span><span class="p">.</span><span class="n">dayofweek</span>
<span class="c1"># Days in a year: 1-365 (or 366)
</span><span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">day_of_year</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">pickup_datetime</span><span class="sh">'</span><span class="p">].</span><span class="n">dt</span><span class="p">.</span><span class="n">dayofyear</span>
<span class="c1"># Time of the  trip
</span><span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">trip_duration</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">dropoff_datetime</span><span class="sh">'</span><span class="p">]</span><span class="o">-</span> <span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">pickup_datetime</span><span class="sh">'</span><span class="p">]).</span><span class="n">dt</span><span class="p">.</span><span class="n">seconds</span>

<span class="c1"># Remove unnecessary datetime columns
</span><span class="n">df_taxi</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="sh">'</span><span class="s">pickup_datetime</span><span class="sh">'</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">df_taxi</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="sh">'</span><span class="s">dropoff_datetime</span><span class="sh">'</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>


<span class="nf">display</span><span class="p">(</span><span class="n">df_taxi</span><span class="p">.</span><span class="nf">head</span><span class="p">())</span>
<span class="nf">print</span><span class="p">(</span><span class="n">df_taxi</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pickup_latitude</th>
      <th>pickup_longitude</th>
      <th>dropoff_latitude</th>
      <th>dropoff_longitude</th>
      <th>min_of_day</th>
      <th>day_of_week</th>
      <th>day_of_year</th>
      <th>trip_duration</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>175062.677585</td>
      <td>1.043488e+06</td>
      <td>216099.139768</td>
      <td>9.886281e+05</td>
      <td>958</td>
      <td>1</td>
      <td>304</td>
      <td>3720</td>
    </tr>
    <tr>
      <th>1</th>
      <td>213727.400082</td>
      <td>9.831375e+05</td>
      <td>175062.677585</td>
      <td>1.043488e+06</td>
      <td>637</td>
      <td>2</td>
      <td>214</td>
      <td>3300</td>
    </tr>
    <tr>
      <th>2</th>
      <td>175062.677585</td>
      <td>1.043488e+06</td>
      <td>231458.376056</td>
      <td>9.938073e+05</td>
      <td>1437</td>
      <td>5</td>
      <td>301</td>
      <td>2160</td>
    </tr>
    <tr>
      <th>3</th>
      <td>209001.626630</td>
      <td>9.868942e+05</td>
      <td>201915.790276</td>
      <td>9.851041e+05</td>
      <td>921</td>
      <td>0</td>
      <td>79</td>
      <td>540</td>
    </tr>
    <tr>
      <th>4</th>
      <td>216099.139768</td>
      <td>9.886281e+05</td>
      <td>213727.400082</td>
      <td>9.831375e+05</td>
      <td>704</td>
      <td>2</td>
      <td>165</td>
      <td>480</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(1967472, 8)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Save the dataset with new features
</span><span class="n">df_taxi</span><span class="p">.</span><span class="nf">to_parquet</span><span class="p">(</span><span class="sh">"</span><span class="s">data/raw/yellow/taxi_2023_raw.parquet</span><span class="sh">"</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="handling-spatial-and-temporal-outliers">Handling Spatial and Temporal Outliers</h2>

<p>The boxplot for detecting outliers relies on the assumption that the data has a distribution close to normal (Gaussian), which is often not true with geospatial coordinates due to their unique patterns influenced by urban roads and traffic. Therefore, we will use a different approach to identify outliers in the location features.</p>

<p>For pickup and dropoff locations, the strategy is to use geospatial data using the taxi <a href="https://d37ci6vzurychx.cloudfront.net/misc/taxi_zones.zip">Taxi Zone Shapefile</a> to identify with any points falls outside the boundaries of NYC map as outliers.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_taxi</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_parquet</span><span class="p">(</span><span class="sh">'</span><span class="s">data/raw/yellow/taxi_2023_raw.parquet</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plot_points_map</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">gdf_map</span><span class="p">,</span> <span class="n">geometry_col</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="sh">''</span><span class="p">,</span> 
                    <span class="n">color_map</span><span class="o">=</span><span class="sh">'</span><span class="s">beige</span><span class="sh">'</span><span class="p">,</span> <span class="n">color_points</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Plots a map with points from a DataFrame with coordinates.

    Parameters:
    - df: DataFrame with the coordinates to plot.
    - gdf_map: GeoDataFrame of the map boundaries.
    - geometry_col: GeoDataFrame column with geometry data.
    - ax: Matplotlib Axes object to plot on.
    - title: Title of the plot.
    - color_map: Color for the map.
    - color_points: Color for the points.
    </span><span class="sh">"""</span>
    <span class="c1"># convert to the same coordinate reference system
</span>    <span class="n">gdf_points</span> <span class="o">=</span> <span class="n">gpd</span><span class="p">.</span><span class="nc">GeoDataFrame</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">geometry</span><span class="o">=</span><span class="n">geometry_col</span><span class="p">)</span>
    <span class="c1"># convert to the same coordinate reference system
</span>    <span class="n">gdf_points</span><span class="p">.</span><span class="n">crs</span> <span class="o">=</span> <span class="n">gdf_map</span><span class="p">.</span><span class="n">crs</span>
        
    <span class="c1"># Plot the map and the points
</span>    <span class="n">gdf_map</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color_map</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">grey</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">gdf_points</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">ax</span> <span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="n">color_points</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Longitude</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Latitude</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">df</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># path of shape file
</span><span class="n">nybb_path</span> <span class="o">=</span> <span class="sh">'</span><span class="s">data/external/nyc-taxi-zones/taxi_zones.shp</span><span class="sh">'</span>
<span class="n">nyc_boundary</span> <span class="o">=</span> <span class="n">gpd</span><span class="p">.</span><span class="nf">read_file</span><span class="p">(</span><span class="n">nybb_path</span><span class="p">)</span>

<span class="c1"># Creating the geometry for points
</span><span class="n">geometry</span> <span class="o">=</span> <span class="n">gpd</span><span class="p">.</span><span class="nf">points_from_xy</span><span class="p">(</span><span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">pickup_longitude</span><span class="sh">'</span><span class="p">],</span> <span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">pickup_latitude</span><span class="sh">'</span><span class="p">])</span>

<span class="c1"># Creating the plot
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="n">pickup_within_nyc</span> <span class="o">=</span> <span class="nf">plot_points_map</span><span class="p">(</span>    <span class="n">df</span> <span class="o">=</span> <span class="n">df_taxi</span><span class="p">,</span> <span class="n">gdf_map</span> <span class="o">=</span> <span class="n">nyc_boundary</span><span class="p">,</span> 
                                        <span class="n">geometry_col</span> <span class="o">=</span> <span class="n">geometry</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">,</span> <span class="n">title</span> <span class="o">=</span>  <span class="sh">'</span><span class="s">Pickup Locations</span><span class="sh">'</span><span class="p">,</span>
                                        <span class="n">color_map</span><span class="o">=</span> <span class="sh">'</span><span class="s">#d9cebfff</span><span class="sh">'</span><span class="p">,</span> <span class="n">color_points</span><span class="o">=</span> <span class="sh">'</span><span class="s">#4759A1</span><span class="sh">'</span><span class="p">)</span> 

<span class="c1"># Showing the plot
</span><span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

</code></pre></div></div>

<center>
<img src="/assets/img/post6/pickup_location.png" width="800" height="800" />
</center>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">geometry</span> <span class="o">=</span> <span class="n">gpd</span><span class="p">.</span><span class="nf">points_from_xy</span><span class="p">(</span><span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">dropoff_longitude</span><span class="sh">'</span><span class="p">],</span> 
                                <span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">dropoff_latitude</span><span class="sh">'</span><span class="p">])</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="n">dropoff_within_nyc</span> <span class="o">=</span> <span class="nf">plot_points_map</span><span class="p">(</span>    <span class="n">df</span> <span class="o">=</span> <span class="n">df_taxi</span><span class="p">,</span> <span class="n">gdf_map</span> <span class="o">=</span> <span class="n">nyc_boundary</span><span class="p">,</span> 
                                                <span class="n">geometry_col</span> <span class="o">=</span> <span class="n">geometry</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">,</span> <span class="n">title</span> <span class="o">=</span>  <span class="sh">'</span><span class="s">Dropoff Locations</span><span class="sh">'</span><span class="p">,</span>
                                                <span class="n">color_map</span><span class="o">=</span> <span class="sh">'</span><span class="s">#d9cebfff</span><span class="sh">'</span><span class="p">,</span> <span class="n">color_points</span><span class="o">=</span> <span class="sh">'</span><span class="s">#4759A1</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<center>
<img src="/assets/img/post6/dropoff_location.png" width="800" height="800" />
</center>

<p>By checking the pickup and dropoff zones, it can be observed that all points are coherent, and there are no outliers for the locations.</p>

<p>To visualize the temporal outliers from trip duration, a boxplot combined with a bar plot for the distributions will be used.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">boxplot_stats</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">whis</span> <span class="o">=</span> <span class="mf">1.5</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Calculate the statistics for a box plot.

    Returns:
    dict: A dictionary containing the quartiles, IQR, and whisker limits.
    </span><span class="sh">"""</span>
    <span class="n">Q1</span> <span class="o">=</span> <span class="n">series</span><span class="p">.</span><span class="nf">quantile</span><span class="p">(</span><span class="mf">0.25</span><span class="p">)</span>
    <span class="n">Q2</span> <span class="o">=</span> <span class="n">series</span><span class="p">.</span><span class="nf">quantile</span><span class="p">(</span><span class="mf">0.50</span><span class="p">)</span>
    <span class="n">Q3</span> <span class="o">=</span> <span class="n">series</span><span class="p">.</span><span class="nf">quantile</span><span class="p">(</span><span class="mf">0.75</span><span class="p">)</span>
    <span class="n">IQR</span> <span class="o">=</span> <span class="n">Q3</span> <span class="o">-</span> <span class="n">Q1</span>

    <span class="n">lower_whisker</span> <span class="o">=</span> <span class="n">Q1</span> <span class="o">-</span> <span class="n">whis</span> <span class="o">*</span> <span class="n">IQR</span>
    <span class="n">upper_whisker</span> <span class="o">=</span> <span class="n">Q3</span> <span class="o">+</span> <span class="n">whis</span> <span class="o">*</span> <span class="n">IQR</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="sh">'</span><span class="s">Q1</span><span class="sh">'</span><span class="p">:</span> <span class="n">Q1</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">Q2</span><span class="sh">'</span><span class="p">:</span> <span class="n">Q2</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">Q3</span><span class="sh">'</span><span class="p">:</span> <span class="n">Q3</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">IQR</span><span class="sh">'</span><span class="p">:</span> <span class="n">IQR</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">lower_whis</span><span class="sh">'</span><span class="p">:</span> <span class="n">lower_whisker</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">upper_whis</span><span class="sh">'</span><span class="p">:</span> <span class="n">upper_whisker</span>
    <span class="p">}</span>


<span class="k">def</span> <span class="nf">plot_distribution_boxplot</span><span class="p">(</span>  <span class="n">series</span><span class="p">,</span> <span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="sh">''</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">''</span><span class="p">,</span> <span class="n">log1p</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
                                <span class="n">draw_quartiles</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Plot the distribution and boxplot of a series on given axes.

    Args:
    - series (pandas.Series): The series to plot.
    - ax1 (matplotlib.axes.Axes): The axes for the histogram.
    - ax2 (matplotlib.axes.Axes): The axes for the boxplot.
    - title (str): The title of the plot.
    - label (str): The label for the x-axis.
    - log (bool): If True, applies log1p transformation to the series.
    - draw_quartiles (bool): If True, draws quartile lines on the histogram.
    - kde (bool): If True, plots a KDE over the histogram.
    </span><span class="sh">"""</span>
    <span class="k">if</span> <span class="n">log1p</span><span class="p">:</span>
        <span class="n">series</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">log1p</span><span class="p">(</span><span class="n">series</span><span class="p">)</span>
    <span class="n">stats</span> <span class="o">=</span> <span class="nf">boxplot_stats</span><span class="p">(</span><span class="n">series</span><span class="p">)</span>

    <span class="n">sns</span><span class="p">.</span><span class="nf">histplot</span><span class="p">(</span>   <span class="n">series</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">#dfdc7bff</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
                    <span class="n">ax</span><span class="o">=</span><span class="n">ax1</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="n">kde</span><span class="p">,</span> <span class="n">line_kws</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">lw</span><span class="sh">'</span><span class="p">:</span> <span class="mi">2</span><span class="p">})</span>
    <span class="n">ax1</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">title</span><span class="si">}</span><span class="s"> Histogram</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">ax1</span><span class="p">.</span><span class="n">lines</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_color</span><span class="p">(</span><span class="sh">'</span><span class="s">gray</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">ax1</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">ax1</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Count</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>

    <span class="n">sns</span><span class="p">.</span><span class="nf">boxplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">series</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">#dfdc7bff</span><span class="sh">'</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax2</span><span class="p">,</span>
                <span class="n">fliersize</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">flierprops</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">color</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">#50566dff</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">markeredgecolor</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">#50566dff</span><span class="sh">'</span><span class="p">})</span>
    
    <span class="n">ax2</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">title</span><span class="si">}</span><span class="s"> Boxplot</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">ax2</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">draw_quartiles</span><span class="p">:</span>
        <span class="n">quartiles</span> <span class="o">=</span> <span class="p">[</span><span class="n">stats</span><span class="p">[</span><span class="sh">'</span><span class="s">Q1</span><span class="sh">'</span><span class="p">],</span> <span class="n">stats</span><span class="p">[</span><span class="sh">'</span><span class="s">Q3</span><span class="sh">'</span><span class="p">],</span> <span class="n">stats</span><span class="p">[</span><span class="sh">'</span><span class="s">lower_whis</span><span class="sh">'</span><span class="p">],</span> <span class="n">stats</span><span class="p">[</span><span class="sh">'</span><span class="s">upper_whis</span><span class="sh">'</span><span class="p">]]</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">quartiles</span><span class="p">:</span>
            <span class="n">ax1</span><span class="p">.</span><span class="nf">axvline</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">#50566dff</span><span class="sh">'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">y_center</span> <span class="o">=</span> <span class="n">ax1</span><span class="p">.</span><span class="nf">get_ylim</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="n">ax1</span><span class="p">.</span><span class="nf">text</span><span class="p">(</span>   <span class="n">line</span><span class="p">,</span> <span class="n">y_center</span><span class="p">,</span> <span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">line</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">,</span>
                        <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="sh">'</span><span class="s">center</span><span class="sh">'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>


</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="nf">plot_distribution_boxplot</span><span class="p">(</span>  <span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">trip_duration</span><span class="sh">'</span><span class="p">],</span> <span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">,</span>
                            <span class="n">title</span><span class="o">=</span><span class="sh">'</span><span class="s">Trip Duration</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Log of Trip Duration (s)</span><span class="sh">'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<center>
<img src="/assets/img/post6/trip_duration_distribution.png" width="800" height="500" />
</center>

<p>Because of the high values and possible zeros in the target feature <code class="language-plaintext highlighter-rouge">trip_duration</code>, we apply the logarithmic transformation $\log(x+1)$. This transformation reduces the effect of outliers and the overall variance in the dataset. Additionally, $\log(x+1)$ is particularly useful for handling zero values because the transformation ensures that zero values are transformed to zero instead of resulting in undefined values. The histogram, illustrated in the first plot, resembles a bell curve after applying this transformation. From the boxplot, we can see:</p>

<ul>
  <li>
    <p>The first and third quartiles ($Q_1$ and $Q_3$) representing the 25th and 75th percentiles, are:</p>

    <ul>
      <li>$Q_1 = 6.18$</li>
      <li>$Q_3 = 7.14$</li>
    </ul>
  </li>
  <li>The interquartile range (IQR) is the difference between the third and first quartiles:
    <ul>
      <li>IQR = $Q_3 - Q_1 = 0.96$</li>
    </ul>
  </li>
  <li>The whiskers indicate the range of the data:
    <ul>
      <li>The lower whisker :  $Q_1 - 1.5 IQR = 4.74$</li>
      <li>The upper whisker :  $Q_3 + 1.5 IQR = 8.58$</li>
    </ul>
  </li>
</ul>

<p>Data points outside the whiskers are potential outliers that need further validation. For better intuition, we convert these whisker values from the log scale back to the original scale in terms of hours ($\text{Hours} = \text{Seconds}/3600$ ):</p>

<p>\(\frac{\exp(4.74) - 1}{3600} \approx  0.031 ~~\text{hours}\)
\(\frac{\exp(8.58) - 1}{3600} \approx  1.48 ~~\text{hours}\)</p>

<p>The lower whisker corresponds to approximately 1.4 minutes, which is very short for a taxi trip duration, suggesting that these could be errors or special cases like short trips to airport to carry bagge. The upper whisker suggests a more plausible trip duration of about 1.32 hours, but with very unrealistic high values with more than 20 hours of duration.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">count_outliers</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">whis</span> <span class="o">=</span> <span class="mf">1.5</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Count the number of upper and lower outliers in the series and print their percentages.

        Args:
        series (pd.Series): Series for which to count outliers.

        Returns:
        (pd.Series, pd.Series): Two boolean series, one for upper outliers and one for lower outliers.
        </span><span class="sh">"""</span>

        <span class="n">stats</span> <span class="o">=</span> <span class="nf">boxplot_stats</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">whis</span><span class="p">)</span>


        <span class="n">upper_outliers</span> <span class="o">=</span> <span class="p">(</span><span class="n">series</span> <span class="o">&gt;</span> <span class="n">stats</span><span class="p">[</span><span class="sh">'</span><span class="s">upper_whis</span><span class="sh">'</span><span class="p">])</span>
        <span class="n">lower_outliers</span> <span class="o">=</span> <span class="p">(</span><span class="n">series</span> <span class="o">&lt;</span> <span class="n">stats</span><span class="p">[</span><span class="sh">'</span><span class="s">lower_whis</span><span class="sh">'</span><span class="p">])</span>

        <span class="c1"># Percentage of outliers 
</span>        <span class="n">percentage_upper</span> <span class="o">=</span> <span class="n">upper_outliers</span><span class="p">.</span><span class="nf">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">series</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
        <span class="n">percentage_lower</span> <span class="o">=</span> <span class="n">lower_outliers</span><span class="p">.</span><span class="nf">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">series</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>

        <span class="nf">print</span><span class="p">(</span>  <span class="sa">f</span><span class="sh">'</span><span class="se">\n</span><span class="s">Potential upper outliers: </span><span class="si">{</span><span class="n">upper_outliers</span><span class="p">.</span><span class="nf">sum</span><span class="p">()</span><span class="si">}</span><span class="s"> </span><span class="sh">'</span>
                <span class="sa">f</span><span class="sh">'</span><span class="s">(</span><span class="si">{</span><span class="n">percentage_upper</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">% of the dataset)</span><span class="sh">'</span><span class="p">)</span>

        <span class="nf">print</span><span class="p">(</span>  <span class="sa">f</span><span class="sh">'</span><span class="se">\n</span><span class="s">Potential lower outliers: </span><span class="si">{</span><span class="n">lower_outliers</span><span class="p">.</span><span class="nf">sum</span><span class="p">()</span><span class="si">}</span><span class="s"> </span><span class="sh">'</span>
                <span class="sa">f</span><span class="sh">'</span><span class="s">(</span><span class="si">{</span><span class="n">percentage_lower</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">% of the dataset)</span><span class="sh">'</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">upper_outliers</span><span class="p">,</span> <span class="n">lower_outliers</span>


<span class="n">log_trip_duration</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">log1p</span><span class="p">(</span><span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">trip_duration</span><span class="sh">'</span><span class="p">])</span>
<span class="n">upper_duration_outliers</span><span class="p">,</span> <span class="n">lower_duration_outliers</span> <span class="o">=</span> <span class="nf">count_outliers</span><span class="p">(</span><span class="n">log_trip_duration</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Potential upper outliers: 4695 (0.24% of the dataset)

Potential lower outliers: 26676 (1.36% of the dataset)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># bar plot for upper whisker
</span><span class="n">upper_outliers</span> <span class="o">=</span> <span class="n">df_taxi</span><span class="p">[</span><span class="n">upper_duration_outliers</span><span class="p">][</span><span class="sh">'</span><span class="s">trip_duration</span><span class="sh">'</span><span class="p">].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span><span class="o">/</span><span class="mi">3600</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">histplot</span><span class="p">(</span>  <span class="n">upper_outliers</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">#dfdc7bff</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">axes</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">High Trip Duration Outliers</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">axes</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Trip Duration (hours)</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>


<span class="c1"># bar plot for lower whisker
</span><span class="n">lower_outliers</span> <span class="o">=</span> <span class="n">df_taxi</span><span class="p">[</span><span class="n">lower_duration_outliers</span><span class="p">][</span><span class="sh">'</span><span class="s">trip_duration</span><span class="sh">'</span><span class="p">].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span><span class="o">/</span><span class="mi">3600</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">histplot</span><span class="p">(</span>  <span class="n">lower_outliers</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">#dfdc7bff</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">axes</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Low Trip Duration Outliers</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">axes</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Trip Duration (hours)</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<center>
<img src="/assets/img/post6/lower_trip_before.png" width="800" height="400" />
</center>

<center>
<img src="/assets/img/post6/lower_trip_after.png" width="800" height="400" />
</center>

<p>Based on the observation plots, it is reasonable to drop records lower then one minute and higher then 4 hours:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">## Select only trip duration above the lower whisker (above 1 minute)
</span><span class="n">df_taxi</span> <span class="o">=</span> <span class="n">df_taxi</span><span class="p">[</span><span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">trip_duration</span><span class="sh">'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">60</span><span class="p">].</span><span class="nf">copy</span><span class="p">()</span>


<span class="c1">## Select only trip duration lower then 4 hours
</span><span class="n">df_taxi</span> <span class="o">=</span> <span class="n">df_taxi</span><span class="p">[</span><span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">trip_duration</span><span class="sh">'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">4</span> <span class="o">*</span> <span class="mi">3600</span><span class="p">].</span><span class="nf">copy</span><span class="p">()</span>

<span class="n">df_taxi</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(1952212, 8)
</code></pre></div></div>

<p>To optimize the performance of the neural network models, it is important to transform and normalize the data. Log transformation and normalization help in achieving better results by addressing skewness, reducing the impact of outliers, and ensuring that all features contribute equally to the model.</p>

<p>First, a logarithmic transformation is applied to the target variable <code class="language-plaintext highlighter-rouge">trip_duration</code>. Since zero values have been removed from the dataset, the standard logarithmic transformation can be safely used without encountering undefined values. Next, normalization is applied to the other dependent variables. Normalizing the data ensures that all features have a mean of 0 and a standard deviation of 1</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Transform target column using log1p
</span><span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">trip_duration</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">log1p</span><span class="p">(</span><span class="n">df_taxi</span><span class="p">[</span><span class="sh">'</span><span class="s">trip_duration</span><span class="sh">'</span><span class="p">])</span>

<span class="c1"># Normalize data for the BNN
</span><span class="n">df_taxi</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_taxi</span> <span class="o">-</span> <span class="n">df_taxi</span><span class="p">.</span><span class="nf">mean</span><span class="p">())</span> <span class="o">/</span> <span class="n">df_taxi</span><span class="p">.</span><span class="nf">std</span><span class="p">()</span>
</code></pre></div></div>

<p>Let’s check how the variables are distributed:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Adjust the layout to 3x3 to handle 9 plots
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">8</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Create a 3x3 grid
</span>    <span class="n">sns</span><span class="p">.</span><span class="nf">histplot</span><span class="p">(</span><span class="n">df_taxi</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">#dfdc7bff</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="n">df_taxi</span><span class="p">.</span><span class="n">columns</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<center>
<img src="/assets/img/post6/feature_distributions.png" width="800" height="700" />
</center>

<p>The final dataset can be then saved into the <code class="language-plaintext highlighter-rouge">data/processed/yellow_taxi_2023.parquet</code> folder. This will be the data used to train our regression model to predict the yellow taxi trip duration in NYC.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_taxi</span><span class="p">.</span><span class="nf">to_parquet</span><span class="p">(</span><span class="sh">"</span><span class="s">data/processed/yellow_taxi_2023.parquet</span><span class="sh">"</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<h1 id="simple-neural-network">Simple Neural Network</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load the processed data
</span><span class="n">df_taxi</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_parquet</span><span class="p">(</span><span class="sh">"</span><span class="s">data/processed/yellow_taxi_2023.parquet</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Split the data into train, validation adn test
</span><span class="n">df_train_large</span><span class="p">,</span> <span class="n">df_taxi_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">df_taxi</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.20</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span> <span class="p">)</span>
<span class="n">df_taxi_train</span><span class="p">,</span> <span class="n">df_taxi_val</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">df_train_large</span><span class="p">,</span> <span class="n">train_size</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>


<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Train large:</span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">df_train_large</span><span class="p">)</span><span class="si">}</span><span class="s">(</span><span class="si">{</span><span class="nf">round</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="nf">len</span><span class="p">(</span><span class="n">df_train_large</span><span class="p">)</span><span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">df_taxi</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s">%)</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Test: </span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">df_taxi_test</span><span class="p">)</span><span class="si">}</span><span class="s">(</span><span class="si">{</span><span class="nf">round</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="nf">len</span><span class="p">(</span><span class="n">df_taxi_test</span><span class="p">)</span><span class="o">/</span><span class="nf">len</span><span class="p">(</span><span class="n">df_taxi</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s">%)</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Train:</span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">df_taxi_train</span><span class="p">)</span><span class="si">}</span><span class="s">(</span><span class="si">{</span><span class="nf">round</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="nf">len</span><span class="p">(</span><span class="n">df_taxi_train</span><span class="p">)</span><span class="o">/</span><span class="nf">len</span><span class="p">(</span><span class="n">df_taxi</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s">%)</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Validation: </span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">df_taxi_val</span><span class="p">)</span><span class="si">}</span><span class="s">(</span><span class="si">{</span><span class="nf">round</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="nf">len</span><span class="p">(</span><span class="n">df_taxi_val</span><span class="p">)</span><span class="o">/</span><span class="nf">len</span><span class="p">(</span><span class="n">df_taxi</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s">%)</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Save Target feature
</span><span class="n">Y_train</span> <span class="o">=</span> <span class="n">df_taxi_train</span><span class="p">[</span><span class="sh">'</span><span class="s">trip_duration</span><span class="sh">'</span><span class="p">].</span><span class="n">values</span>
<span class="n">Y_val</span> <span class="o">=</span> <span class="n">df_taxi_val</span><span class="p">[</span><span class="sh">'</span><span class="s">trip_duration</span><span class="sh">'</span><span class="p">].</span><span class="n">values</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">df_taxi_test</span><span class="p">[</span><span class="sh">'</span><span class="s">trip_duration</span><span class="sh">'</span><span class="p">].</span><span class="n">values</span>

<span class="c1"># Drop target feature
</span><span class="n">df_taxi_train</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="sh">'</span><span class="s">trip_duration</span><span class="sh">'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df_taxi_val</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="sh">'</span><span class="s">trip_duration</span><span class="sh">'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df_taxi_test</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="sh">'</span><span class="s">trip_duration</span><span class="sh">'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">df_taxi_train</span><span class="p">.</span><span class="n">values</span>
<span class="n">X_val</span> <span class="o">=</span> <span class="n">df_taxi_val</span><span class="p">.</span><span class="n">values</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">df_taxi_test</span><span class="p">.</span><span class="n">values</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Train large:1561769(80.0%)
Test: 390443(20.0%)
Train:390442(20.0%)
Validation: 1171327(60.0%)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">NNRegressor</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>
                 <span class="n">layer_units</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">],</span>
                 <span class="n">output_unit</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                 <span class="n">dropout_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
                 <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">NNRegressor</span><span class="sh">"</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Initialize the NNRegressor.

        Args:
            layer_units (list of int): A list of integers representing the number of units in each 
            hidden layer.
            output_unit (int): An integer representing the number of units in the output layer.
            dropout_rate (float): A float representing the dropout rate used in each dropout layer.
            name (str): A string representing the name of the model.
        </span><span class="sh">"""</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">units</span> <span class="o">=</span> <span class="n">layer_units</span>
        <span class="n">self</span><span class="p">.</span><span class="n">output_unit</span> <span class="o">=</span> <span class="n">output_unit</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dropout_rate</span> <span class="o">=</span> <span class="n">dropout_rate</span>

        <span class="c1"># Hidden layers
</span>        <span class="n">self</span><span class="p">.</span><span class="n">hidden_layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">unit</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">layer_units</span><span class="p">):</span>
            <span class="n">self</span><span class="p">.</span><span class="n">hidden_layers</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">unit</span><span class="p">,</span>                                          
                                           <span class="n">use_bias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                                           <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="sh">'</span><span class="s">Hidden_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="sh">'</span><span class="p">))</span>
            <span class="n">self</span><span class="p">.</span><span class="n">hidden_layers</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nc">BatchNormalization</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="sh">'</span><span class="s">BatchNorm_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="sh">'</span><span class="p">))</span>
            <span class="n">self</span><span class="p">.</span><span class="n">hidden_layers</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nc">ReLU</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="sh">'</span><span class="s">ReLU_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="sh">'</span><span class="p">))</span>
            <span class="n">self</span><span class="p">.</span><span class="n">hidden_layers</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nc">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="sh">'</span><span class="s">Dropout_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="sh">'</span><span class="p">))</span>

        <span class="c1"># Output layer
</span>        <span class="n">self</span><span class="p">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">output_unit</span><span class="p">,</span>
                                  <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">Output</span><span class="sh">"</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Compute the forward pass of the NNRegressor.

        Args:
            x (tf.Tensor): A tensor of shape (batch_size, input_dim), where input_dim is the dimension of the 
            input features.

        Returns:
            tf.Tensor: A tensor of shape (batch_size, output_unit), containing the output of the NNRegressor.
        </span><span class="sh">"""</span>

        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">hidden_layers</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="nf">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">output_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>

</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Instantiate and compile the model
</span><span class="n">nn_regressor</span> <span class="o">=</span> <span class="nc">NNRegressor</span><span class="p">()</span>
<span class="n">nn_regressor</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="nc">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">),</span> <span class="n">loss</span><span class="o">=</span><span class="sh">'</span><span class="s">mean_absolute_error</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Train the model with explicit validation data
</span><span class="n">nn_history</span> <span class="o">=</span> <span class="n">nn_regressor</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> 
                             <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">Y_val</span><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Save Model
</span><span class="n">current_directory</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="nf">getcwd</span><span class="p">()</span>
<span class="n">save_dir</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">expanduser</span><span class="p">(</span> <span class="n">current_directory</span> <span class="o">+</span> <span class="sh">'</span><span class="s">/models/nn_regressor</span><span class="sh">'</span><span class="p">)</span>
<span class="n">nn_regressor</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">save_dir</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/150
382/382 [==============================] - 19s 47ms/step - loss: 0.5925 - val_loss: 0.4669
Epoch 2/150
382/382 [==============================] - 18s 47ms/step - loss: 0.4891 - val_loss: 0.4025
Epoch 3/150
382/382 [==============================] - 18s 46ms/step - loss: 0.4642 - val_loss: 0.3991
.
.
.
Epoch 150/150
382/382 [==============================] - 18s 46ms/step - loss: 0.3729 - val_loss: 0.3643
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">nn_history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">loss</span><span class="sh">'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Train</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span>  <span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">nn_history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">val_loss</span><span class="sh">'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Validation</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span>  <span class="sh">"</span><span class="s">#d08f10ff</span><span class="sh">"</span> <span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">MAE vs Epochs</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Epoch</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">MAE</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

</code></pre></div></div>

<center>
<img src="/assets/img/post6/lr_curve_ann.png" width="600" height="400" />
</center>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_mae_log</span> <span class="o">=</span> <span class="mf">0.38</span>
<span class="n">val_mae_log</span> <span class="o">=</span> <span class="mf">0.37</span>

<span class="n">train_mae_original</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">train_mae_log</span><span class="p">)</span>
<span class="n">val_mae_original</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">val_mae_log</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Original scale train MAE: </span><span class="si">{</span><span class="n">train_mae_original</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> seconds</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Original scale validation MAE: </span><span class="si">{</span><span class="n">val_mae_original</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> seconds</span><span class="sh">"</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Original scale train MAE: 1.46 seconds
Original scale validation MAE: 1.45 seconds
</code></pre></div></div>

<p>After back-transforming the MAE values from the log scale, the results indicate that the predictions deviate from the actual values by a factor of approximately 1.47 for the training set and 1.45 for the validation set. This is because the log transformation turns multiplicative errors into additive ones. When exponentiating the log-scale MAE, it reflects the average multiplicative error. For an actual trip duration of 500 seconds, this means:</p>

<ul>
  <li>
    <p>Train MAE: The predictions would be off by a factor of 1.47. Therefore, $1.47 \times 500≈7351.47  \times 500≈735$ seconds.</p>
  </li>
  <li>
    <p>Validation MAE: The predictions would be off by a factor of 1.45. Therefore, $1.45 \times 500≈7251.45  \times 500≈725$ seconds.</p>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Make predictions on the test set
</span><span class="n">preds</span> <span class="o">=</span> <span class="n">nn_regressor</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Select a sample of predictions to plot
</span><span class="n">sample_indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">Y_test</span><span class="p">)),</span> <span class="n">size</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">sample_preds</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[</span><span class="n">sample_indices</span><span class="p">]</span>
<span class="n">sample_true</span> <span class="o">=</span> <span class="n">Y_test</span><span class="p">[</span><span class="n">sample_indices</span><span class="p">]</span>

<span class="c1"># Plot true vs predicted durations
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span> 
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">9</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># 3 rows, 3 columns
</span>    <span class="n">plt</span><span class="p">.</span><span class="nf">axvline</span><span class="p">(</span><span class="n">sample_preds</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Predicted</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">#dfdc7bff</span><span class="sh">'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">axvline</span><span class="p">(</span><span class="n">sample_true</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="sh">'</span><span class="s">:</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">True</span><span class="sh">'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">gca</span><span class="p">().</span><span class="nf">get_yaxis</span><span class="p">().</span><span class="nf">set_ticklabels</span><span class="p">([])</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">6</span><span class="p">:</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">gca</span><span class="p">().</span><span class="nf">get_xaxis</span><span class="p">().</span><span class="nf">set_ticklabels</span><span class="p">([])</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>12202/12202 [==============================] - 14s 1ms/step
</code></pre></div></div>

<center>
<img src="/assets/img/post6/trip_duration_predict.png" width="800" height="600" />
</center>

<p>The provided plot shows a comparison between predicted and true trip durations for a sample of 9 trips from the test set. Each subplot represents a single trip, showing the predicted duration as a solid line and the true duration as a dashed line.</p>

<p>Neural networks typically provide point estimates for predictions, meaning they output a single predicted value for each input. Point estimates do not provide information about the uncertainty or confidence in the predictions. This is a significant limitation because it means we can’t quantify how confident the model is about its predictions.</p>

<p>For example, in a taxi trip, knowing the uncertainty in trip duration helps passengers plan their activities better. For example, ff a passenger has a flight to catch, understanding the potential range of travel times can help them decide when to leave for the airport.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nn_preds</span> <span class="o">=</span> <span class="n">nn_regressor</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># distributions plot
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># KDE plot for residuals
</span><span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">kdeplot</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">#dfdc7bff</span><span class="sh">"</span> <span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">True</span><span class="sh">'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">kdeplot</span><span class="p">(</span><span class="n">nn_preds</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">#d08f10ff</span><span class="sh">"</span><span class="p">,</span>  <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Predicted</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Density</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Distribution (KDE)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># CDF plot
</span><span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">kdeplot</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">cumulative</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">#dfdc7bff</span><span class="sh">"</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">True</span><span class="sh">'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">kdeplot</span><span class="p">(</span><span class="n">nn_preds</span><span class="p">,</span> <span class="n">cumulative</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">#d08f10ff</span><span class="sh">"</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>  <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Predicted</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">CDF</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Cumulative Distribution (CDF)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>12202/12202 [==============================] - 22s 2ms/step
</code></pre></div></div>

<center>
<img src="/assets/img/post6/ann_distribution_true_pred.png" width="800" height="300" />
</center>

<p>The plot compares the distributions of true and predicted taxi trip durations using a Neural Network (NN) model. The KDE and CDF plots shows that the neural network model provides a good fit to the taxi trip duration data, with predicted values closely matching the true values. While there are some minor discrepancies in the tails of the distribution, the overall alignment suggests that the model is effective at capturing the underlying patterns in the data.</p>

<h1 id="simple-bayesian-neural-network"><strong>Simple Bayesian Neural Network</strong></h1>

<p>To incorporate uncertainty information, we will use Bayesian Neural Networks (BNNs). BNNs provide not only point estimates but also a measure of uncertainty, which allows for more informed decision-making. Because fitting a BNN using Keras is challenging, the idea is to create the model from scratch using TensorFlow and Keras API. We first began by creating a dense variational layer that receives the number of neurons and the activation function, similar to a standard layer in TensorFlow.</p>

<p>To illustrate the feedforward step in a Bayesian Neural Network (BNN), consider a BNN with two layers, where  $\mathbf{x}$  is a vector consisting of  $m$  neurons in the input layer, and  $\mathbf{y}$  is a vector consisting of  $n$   neurons in the output layer:</p>

<center>
<img src="/assets/img/post6/bnn_ff_2layer.svg" width="800" height="600" />
</center>

<p>For a BNN, weights and biases are not just fixed values. Instead, each weight and bias is associated with a mean and a variance, which are parameters of the normal distribution from which they are sampled at each forward step. This introduces variability in the weights and biases, allowing BNNs to inherently model uncertainty. A standard approach is the reparametrization trick to sample the weight and bias values from their respective independent normal distributions and to guarantee differentiability during the backpropagation step. To further understand, consider the weights and biases between the input and hidden layers:</p>

\[w_{ij} = \mu_{ij} + \sigma_{ij} \cdot \epsilon_{ij}\]

\[b_{j} = \mu_{j} + \sigma_{j} \cdot \epsilon_{j}\]

<p>To initialize the learnable variables $\mu_{ij}$ and $\sigma_{ij}$ for the distribution of the weights and biases, we can sample random values from a truncated normal distribution, represented as $\mathcal{T}\left(0, \sqrt{\frac{2}{n+m}}\right)$. This is done within the <code class="language-plaintext highlighter-rouge">xavier</code> method of the class. This particular distribution ensures that the initialized weights and biases aren’t too distant from the mean, as extreme values might negatively affect the learning process. The matrix representation for the mean and variance of weights and biases are:</p>

\[{\mu}_w =
\left( \begin{array}{cccc}
\mu_{11} &amp; \cdots &amp; \mu_{1n}\\
\vdots &amp; \ddots &amp; \vdots\\
\mu_{m1} &amp; \cdots &amp;\mu_{mn}
\end{array} \right)~~~~
{\Sigma}_w =
\left( \begin{array}{cccc}
\sigma_{11} &amp; \cdots &amp; \sigma_{1n}\\
\vdots &amp; \ddots &amp; \vdots\\
\sigma_{m1} &amp; \cdots &amp;\sigma_{mn}
\end{array} \right).\]

<p>and</p>

\[{\mu}_b =
\left( \begin{array}{c}
\mu_{1} \\
\vdots \\
\mu_{n}
\end{array} \right)~~~~
{\Sigma}_b =
\left( \begin{array}{c}
\sigma_{1}\\
\vdots\\
\sigma_{n}
\end{array} \right).\]

<p>Here, each $w_{ij}$ connects the $i$-th neuron in the input layer to the $j$-th neuron in the next layer, sampled from a normal distribution $\mathcal{N}(\mu_{ij}, \sigma_{ij})$, where $\mu_{ij}$ and $\sigma_{ij}$ are learnable parameters for the mean and standard deviation, and $\epsilon_{ij}$ is the perturbation sampled from a normal distribution $\mathcal{N}(0, 1)$. The same idea applies to the bias term $b_{j}$. In matrix notation, for all connections of the weights and biases between the two layers, we have:</p>

\[\mathbf{W} = \mu_w + \Sigma_w \odot \epsilon_w\]

\[\mathbf{b} = \mu_b + \Sigma_b \odot \epsilon_b\]

<p>where</p>

\[\mathbf{W} =
\left( \begin{array}{cccc}
w_{11} &amp; \cdots &amp; w_{1n}\\
\vdots &amp; \ddots &amp; \vdots\\
w_{m1} &amp; \cdots &amp;w_{mn}
\end{array} \right),~~~~
\mathbf{b} =
\left( \begin{array}{c}
b_{1}\\
\vdots\\
b_{n}
\end{array} \right)\]

<p>So to sample the matrix $\mathbf{W}$ for the weights of a layer, we calculate the posterior normal distribution $p(\mathbf{w} \mid \mathbf{x}) \sim \mathcal{N}(\mu_{w}, \Sigma_{w})$ given the input data $\mathbf{x}$.</p>

<p>However, there is a computational problem with this approach: the reparameterization trick can use the same noise $\epsilon_{ij}$ for the entire batch. This means that for a given batch, all the weight samples share the same noise term, which introduces correlation across different samples within the batch. This correlation leads to noisy gradient estimates because each gradient update is influenced by the same noise terms.</p>

<p>To address this issue, we need a way to decorrelate these samples to ensure that the noise affecting the weights and biases is different for each forward step within the batch. The <a href="https://arxiv.org/abs/1803.04386">Flipout method</a> can be used for this purpose. Flipout introduces additional perturbations with random sign matrices (matrices with $\pm 1$ entries), which effectively decorrelates the samples across different forward passes within a batch.</p>

<p>The Flipout method uses clever perturbations to implicitly sample from the weight and bias distributions without using the same perturbation for each batch. This is achieved by creating perturbations in the input batch matrix $\mathbf{x_i}$ from the previous layer and also by multiplying the noise $\epsilon$ by random sign matrices. This ensures that the perturbations are different for each batch, reducing the correlation introduced by using the same distribution to sample the noise $\epsilon$ across the entire batch.</p>

<p>Flipout use a base perturbation  $\epsilon$   shared by all examples in the batch and multiplies it by a different sign matrix for each example:</p>

\[\epsilon_i = \epsilon \odot (\mathbf{r_i} \mathbf{s_i^T})\]

<p>where  $\mathbf{r_i}$   and  $\mathbf{s_i}$   are random vectors whose entries are sampled uniformly from  $\pm 1$  .</p>

<p>Considering the previous illustration of a BNN with two layers, the feedforward step for the  $i$-th batch  $\mathbf{x_i}$   would have the following structure without Flipout:</p>

\[\left\{ \begin{array}{ll} 
\mathbf{\textrm{net}} = \mathbf{x_i} \cdot \mathbf{W} \\
\mathbf{y_i} = f \left(\mathbf{\textrm{net}}\right)
\end{array}\right.\]

<p>where  $f(.)$   is the activation function. For simplicity, we will only focus on the weight term. To sample  $\mathbf{W}$   by using the Flipout method, we would have:</p>

\[\mathbf{W} = \mu_{w} + \Sigma_{w} \odot \epsilon_i\]

<p>The formulation is similar to the reparameterization trick to sample the weights, with the difference being the perturbation term. Substituting in the  $\textrm{net}$   equation:</p>

\[\begin{align*}
\mathbf{\textrm{net}} &amp;= \mathbf{x_i}(\mu + (\Sigma_{w} \odot \epsilon) \odot (\mathbf{r_i} \mathbf{s_i^T}))\\
&amp;= \mathbf{x_i}\mu + (\Sigma_{w} \odot \epsilon) \odot \left((\mathbf{x_i}\odot \mathbf{s_i^T}) \odot \mathbf{r_i})\right) 
\end{align*}\]

<p>This results in the following equation for a batch in the BNN using Flipout:</p>

\[\mathbf{y_i} = f(\mathbf{x_i}\mu + (\Sigma_{w} \odot \epsilon) \odot \left((\mathbf{x_i}\odot \mathbf{s}_i^T) \odot \mathbf{r}_i)\right)\]

<p>This Flipout method is calculated in our <code class="language-plaintext highlighter-rouge">call</code> method for the class DenseFlipout.</p>

<p>For the losses computed in each layer, within the method <code class="language-plaintext highlighter-rouge">layer_losses</code>, we will use the Kullback-Leibler (KL) Divergence (Relative Entropy). The KL divergence is a measure that quantifies the difference or “distance” between two probability distributions. Given two probability distributions for the weights, the posterior distribution $p(\mathbf{W}\mid \mathbf{x}) \sim \mathcal{N}(\mu_{w}, \Sigma_{w})$ and the prior distribution $q(\mathbf{W}) \sim \mathcal{N}(0, 1)$, the KL divergence can be defined using the following equation:</p>

\[D_{KL}(q\mid \mid p) = \int q(\mathbf{W})\log{\bigg(\frac{q(\mathbf{W})}{p(\mathbf{W}\mid \mathbf{x})}\bigg)} dW\]

<p>The KL divergence can be interpreted as the expected logarithmic difference between the two probability distributions, with the expectation taken over the values of $\mathbf{W}$ according to the posterior distribution $p(\mathbf{W}\mid\mathbf{x})$. In essence, the KL divergence quantifies the amount of information lost when we approximate the posterior distribution $p(\mathbf{W} \mid\mathbf{x})$ using the prior distribution $q(\mathbf{W})$.</p>

\[D_{KL}(p\mid \mid q) =\mathbb{E}\bigg[\log{\bigg(\frac{q(\mathbf{W})}{p(\mathbf{W}\mid\mathbf{x})}\bigg)}\bigg]\]

<p>By encouraging the posterior distribution to remain close to the prior (standard normal), we are effectively regularizing the network. This regularization helps to prevent overfitting by penalizing weights that deviate too far from zero, thereby favoring simpler models that generalize better. The goal is to update this prior belief to a posterior distribution after observing the data $\mathbf{x}$. The KL divergence term in the loss function ensures that the learned weights do not stray too far from our prior belief unless supported by the data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">DenseFlipout</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="sh">'</span><span class="s">DenseVariational</span><span class="sh">'</span><span class="p">):</span>
        
        <span class="sh">"""</span><span class="s">
        Initializes the custom variational dense layer with flipout.

        Args:
            units (int): The number of neurons in the dense layer.
            activation (str or callable, optional): The activation function to use on the layer</span><span class="sh">'</span><span class="s">s output. 
                Defaults to None, which means no activation is applied.
            name (str): The name of the layer.
        </span><span class="sh">"""</span>
              
        <span class="nf">super</span><span class="p">(</span><span class="n">DenseFlipout</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">units</span> <span class="o">=</span> <span class="n">units</span>
        <span class="n">self</span><span class="p">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">activations</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">xavier</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>

        <span class="sh">"""</span><span class="s">
        Performs Xavier initialization for the layer</span><span class="sh">'</span><span class="s">s weights and biases.

        Args:
            shape (tuple): The shape of the tensor to initialize.

        Returns:
            tf.Tensor: A tensor with the specified shape initialized using the Xavier initialization method.
        </span><span class="sh">"""</span>
        <span class="n">xavier_dist</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">truncated_normal</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mf">2.0</span> <span class="o">/</span> <span class="nf">sum</span><span class="p">(</span><span class="n">shape</span><span class="p">)))</span>

        <span class="k">return</span> <span class="n">xavier_dist</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>

        <span class="sh">"""</span><span class="s">
        Builds the variational dense layer by initializing weights and biases with their respective means 
        and standard deviations.

        Args:
            input_shape (tuple): The shape of the input to the layer, used to determine the weight shapes.
        </span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="n">d_in</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># Initializing mean and standard deviation
</span>        <span class="n">self</span><span class="p">.</span><span class="n">w_loc</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nc">Variable</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">xavier</span><span class="p">((</span><span class="n">self</span><span class="p">.</span><span class="n">d_in</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">units</span><span class="p">)),</span> <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">w_loc</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">w_std</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nc">Variable</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">xavier</span><span class="p">((</span><span class="n">self</span><span class="p">.</span><span class="n">d_in</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">units</span><span class="p">))</span> <span class="o">-</span> <span class="mf">6.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">w_std</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">b_loc</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nc">Variable</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">xavier</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">units</span><span class="p">)),</span> <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">b_loc</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">b_std</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nc">Variable</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">xavier</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">units</span><span class="p">))</span> <span class="o">-</span> <span class="mf">6.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">b_std</span><span class="sh">'</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">training</span> <span class="o">=</span> <span class="bp">True</span><span class="p">):</span>

        <span class="sh">"""</span><span class="s">
        Performs the forward pass through the layer, either stochastically if in training mode, 
        or deterministically.

        Args:
            x (tf.Tensor): Input tensor to the layer.
            training (bool): Boolean flag indicating whether the layer is in training mode.

        Returns:
            tf.Tensor: Output tensor after applying the variational dense layer.
        </span><span class="sh">"""</span>

        <span class="k">if</span> <span class="n">training</span><span class="p">:</span> <span class="c1"># Stochastic forward pass (sampling process)
</span>            
            <span class="c1"># random sign matrix (+-1 entries) perturbation
</span>            <span class="n">s</span> <span class="o">=</span> <span class="n">tfp</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rademacher</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">shape</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="c1"># Sign matrix for input perturbation
</span>            <span class="n">r</span> <span class="o">=</span> <span class="n">tfp</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rademacher</span><span class="p">([</span><span class="n">tf</span><span class="p">.</span><span class="nf">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">self</span><span class="p">.</span><span class="n">units</span><span class="p">])</span>  <span class="c1"># Sign matrix for output perturbation
</span>            
            <span class="c1"># For Weights
</span>            <span class="c1"># Softplus to ensure std is positive
</span>            <span class="n">w_std_positive</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nf">softplus</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">w_std</span><span class="p">)</span>
            <span class="n">w_noise</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="n">d_in</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">units</span><span class="p">])</span>
            <span class="n">w_flipout_noise</span> <span class="o">=</span> <span class="n">r</span><span class="o">*</span><span class="n">tf</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">x</span><span class="o">*</span><span class="n">s</span> <span class="p">,</span> <span class="n">w_std_positive</span><span class="o">*</span><span class="n">w_noise</span><span class="p">)</span>
            <span class="n">w_sample</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">w_loc</span><span class="p">)</span> <span class="o">+</span> <span class="n">w_flipout_noise</span>
            
            <span class="c1"># For Bias
</span>            <span class="c1"># Softplus to ensure std is positive
</span>            <span class="n">r</span> <span class="o">=</span> <span class="n">tfp</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rademacher</span><span class="p">([</span><span class="n">tf</span><span class="p">.</span><span class="nf">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">self</span><span class="p">.</span><span class="n">units</span><span class="p">])</span>
            <span class="n">b_std_positive</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nf">softplus</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">b_std</span><span class="p">)</span>
            <span class="n">b_noise</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="n">units</span><span class="p">])</span>
            <span class="n">b_flipout_noise</span> <span class="o">=</span> <span class="n">r</span><span class="o">*</span><span class="n">b_std_positive</span><span class="o">*</span><span class="n">b_noise</span>
            <span class="n">b_sample</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">b_loc</span> <span class="o">+</span> <span class="n">b_flipout_noise</span>
            
            
            <span class="n">output</span> <span class="o">=</span> <span class="n">w_sample</span> <span class="o">+</span> <span class="n">b_sample</span>

        <span class="k">else</span><span class="p">:</span> <span class="c1"># Deterministic forward pass
</span>            <span class="n">output</span> <span class="o">=</span>  <span class="n">x</span> <span class="o">@</span> <span class="n">self</span><span class="p">.</span><span class="n">w_loc</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="n">b_loc</span>
        
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">activation</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">activation</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
            
        <span class="k">return</span> <span class="n">output</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">layer_losses</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>

        <span class="sh">"""</span><span class="s">
        Computes the regularization loss for this layer, quantified as the Kullback-Leibler (KL) divergence 
        between the approximate posterior and the prior distributions of the layer</span><span class="sh">'</span><span class="s">s weights and biases. 
        This loss term encourages the weights to remain close to the prior, preventing overfitting and 
        ensuring that the learned representations are robust.

        Returns:
            tf.Tensor: The computed regularization loss for this layer, as a scalar tensor.
        </span><span class="sh">"""</span>

        <span class="c1"># Prior distribution 
</span>        <span class="n">prior</span> <span class="o">=</span> <span class="n">tfd</span><span class="p">.</span><span class="nc">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Posterior distributions
</span>        <span class="c1"># Softplus to ensure std is positive
</span>        <span class="n">weight_posterior</span> <span class="o">=</span> <span class="n">tfd</span><span class="p">.</span><span class="nc">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">w_loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nf">softplus</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">w_std</span><span class="p">))</span>
        <span class="n">bias_posterior</span> <span class="o">=</span> <span class="n">tfd</span><span class="p">.</span><span class="nc">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">b_loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nf">softplus</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">b_std</span><span class="p">))</span>

        <span class="c1"># Kullback-Leibler divergence between posterior and prior distributions
</span>        <span class="n">kl_w</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_sum</span><span class="p">(</span><span class="n">tfd</span><span class="p">.</span><span class="nf">kl_divergence</span><span class="p">(</span><span class="n">weight_posterior</span><span class="p">,</span> <span class="n">prior</span><span class="p">))</span>
        <span class="n">kl_b</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_sum</span><span class="p">(</span><span class="n">tfd</span><span class="p">.</span><span class="nf">kl_divergence</span><span class="p">(</span><span class="n">bias_posterior</span><span class="p">,</span> <span class="n">prior</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">kl_w</span> <span class="o">+</span> <span class="n">kl_b</span>
</code></pre></div></div>

<p>After defining a single Bayesian neural network layer, we can create another class that represents a Bayesian Neural Network (BNN) with multiple layers. This class will aggregate all the layers in the network and account for the KL divergence of each layer. The network_losses property ensures that the total KL divergence is computed by summing the contributions from all layers, which is essential for optimizing the Evidence Lower Bound (ELBO) during training.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">BNN</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>
                 <span class="n">layer_units</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
                 <span class="n">output_unit</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                 <span class="n">activation_func</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">,</span>
                 <span class="n">output_activation</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> 
                 <span class="n">name</span> <span class="o">=</span> <span class="sh">"</span><span class="s">BayesianNN</span><span class="sh">"</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Initializes a Bayesian Neural Network with variational dense layers.

        Args:
            layer_units (list): A list of integers representing the number of units in each hidden layer.
            output_unit (int): The number of units in the output layer.
            activation_func (str): The activation function to use for all hidden layers.
            kl_weight (float): The weight factor for the Kullback-Leibler divergence term in the loss 
            function.
            name (str): The name of the model.
        </span><span class="sh">"""</span>
        

        <span class="nf">super</span><span class="p">(</span><span class="n">BNN</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">layer_units</span> <span class="o">=</span> <span class="n">layer_units</span>
        <span class="n">self</span><span class="p">.</span><span class="n">output_unit</span> <span class="o">=</span> <span class="n">output_unit</span>
        <span class="n">self</span><span class="p">.</span><span class="n">activation_func</span> <span class="o">=</span> <span class="n">activation_func</span>

        <span class="n">self</span><span class="p">.</span><span class="n">layer_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">layer_units</span><span class="p">)):</span>
            <span class="n">self</span><span class="p">.</span><span class="n">layer_list</span> <span class="o">+=</span> <span class="p">[</span> <span class="nc">DenseFlipout</span><span class="p">(</span> <span class="n">units</span><span class="o">=</span><span class="n">layer_units</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                                               <span class="n">activation</span><span class="o">=</span><span class="n">activation_func</span><span class="p">,</span>
                                               <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">DenseVariational_{}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                                               <span class="p">)]</span>
            
        <span class="n">self</span><span class="p">.</span><span class="n">layer_list</span> <span class="o">+=</span> <span class="p">[</span> <span class="nc">DenseFlipout</span><span class="p">(</span>  <span class="n">units</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">output_unit</span><span class="p">,</span>
                                            <span class="n">activation</span> <span class="o">=</span> <span class="n">output_activation</span><span class="p">,</span>
                                            <span class="n">name</span> <span class="o">=</span> <span class="sh">'</span><span class="s">OutputLayer</span><span class="sh">'</span>
                                            <span class="p">)]</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Executes a forward pass through the network.

        Args:
            x (Tensor): The input tensor.

        Returns:
            Tensor: The output of the network after passing through all the layers.
        </span><span class="sh">"""</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">layer_list</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="nf">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
    
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">network_losses</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Aggregates the KL divergence losses from all layers into a single loss term.

        Returns:
            Tensor: The sum of the KL divergence losses from all layers.
        </span><span class="sh">"""</span>
        <span class="c1"># Summing up the KL divergence losses from all variational layers
</span>        <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_sum</span><span class="p">([</span><span class="n">layer</span><span class="p">.</span><span class="n">layer_losses</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">layer_list</span><span class="p">])</span> 
</code></pre></div></div>

<p>Now we can construct our regression model using the BNN with multiple layers. For this part, we desire to construct the BNN with the following structure, as illustrated below:</p>

<center>
<img src="/assets/img/post6/simple-bnn.svg" width="800" height="600" />
</center>

<p>This model gives us predictions of the mean $\mu$ and the standard deviation $\sigma$ based on the input data $\mathbf{x}$. The mean prediction comes from the network by learning the weight parameters sampled from the posterior normal distribution $\mathcal{N}(\mu_{w}, \Sigma_{w})$ defined in the <code class="language-plaintext highlighter-rouge">DenseFlipout</code> layer, where $\mu_{w}$ and $\Sigma_{w}$ are matrices of the learnable parameters for the mean and standard deviation of this posterior distribution. On the other hand, the predicted standard deviation $\sigma$ is modeled using the inverse square root of a gamma distribution $\Gamma(\alpha, \beta)$ with learnable parameters $\alpha$ for the shape and $\beta$ for the rate. During the training process, the model updates these parameters based on the data, resulting in a posterior distribution that best represents the uncertainty in the standard deviation, similar to what we have for the mean.</p>

<p>In this part of the model, the KL divergence is calculated for the prior and posterior gamma distributions and summed with the KL divergence of the normal distribution that comes from the layers, resulting in a total KL divergence for the whole network. This total KL divergence is used to calculate and take the gradient of the Evidence Lower Bound (ELBO) term inside the <code class="language-plaintext highlighter-rouge">_train_evaluate</code> method.</p>

<p>The ELBO term comes from the KL divergence itself, by making some mathematical manipulations on the equation of the KL divergence:</p>

\[D_{KL}(q\mid \mid p) = \int q(\mathbf{W})\log{\bigg(\frac{q(\mathbf{W})}{p(\mathbf{W}\mid  \mathbf{x})}\bigg)} dW.\]

<p>This manipulation decomposes this equation into two terms: the ELBO and the log likelihood of the distribution of the input data $\mathbf{x}$.</p>

\[D_{KL}(q\mid \mid p) = -\mathbb{E}_{\mathbf{W} \sim q}\bigg[\log{\frac{p(\mathbf{x}\mid \mathbf{W})p(\mathbf{W})}{q(\mathbf{W})}}\bigg] + \log{p(\mathbf{x})}\]

<p>The expectation term is the Evidence Lower Bound (ELBO):</p>

\[\text{ELBO}(q(\mathbf{W})) = \mathbb{E}_{\mathbf{W} \sim q}\bigg[\log{\frac{p(\mathbf{D}\mid \mathbf{W})p(\mathbf{W})}{q(\mathbf{W})}}\bigg]\]

<p>The log likelihood term, $\log{p(\mathbf{x})}$, is a constant that depends only on the input data $\mathbf{x}$.</p>

<p>Since the KL divergence must be non-negative, $D_{KL}(q\mid \mid p) \geq 0$, as it measures the information loss between the true posterior distribution $p(\mathbf{W} \mid \mathbf{x})$ and the variational distribution $q(\mathbf{W})$, we have the following inequality:</p>

\[-\text{ELBO}(q(\mathbf{W})) + \log{p(\mathbf{x})}\geq 0\]

<p>This inequality clearly indicates that the ELBO serves as a lower bound to the log marginal likelihood, $\log{p(\mathbf{x})}$, hence the name Evidence Lower Bound. Maximizing the ELBO is equivalent to minimizing the KL divergence between the variational distribution $q(\mathbf{W})$ and the posterior distribution $p(\mathbf{W} \mid \mathbf{x})$. By minimizing the information loss represented by the KL divergence, we are effectively approximating the true posterior with the variational distribution.</p>

<p>For the code below, the ELBO will be the sum of all KL divergences divided by the total size of the input data minus the reduced sum of the log likelihood, where the goal is to minimize the negative ELBO (equivalent to maximizing the ELBO)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">BNNRegressor</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>   
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">layers</span><span class="p">,</span> <span class="n">total_samples</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">BNNRegressor</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="p">)</span>

        <span class="c1"># Trackers for training metrics
</span>        <span class="n">self</span><span class="p">.</span><span class="n">train_elbo_tracker</span> <span class="o">=</span> <span class="nc">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">train_elbo</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">train_mae_tracker</span> <span class="o">=</span> <span class="nc">MeanAbsoluteError</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">train_mae</span><span class="sh">'</span><span class="p">)</span>

        <span class="c1"># Trackers for validation metrics
</span>        <span class="n">self</span><span class="p">.</span><span class="n">val_elbo_tracker</span> <span class="o">=</span> <span class="nc">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">val_elbo</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">val_mae_tracker</span> <span class="o">=</span> <span class="nc">MeanAbsoluteError</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">val_mae</span><span class="sh">'</span><span class="p">)</span>

        <span class="c1"># Variational distribution for observed data
</span>        <span class="n">self</span><span class="p">.</span><span class="n">loc_net</span> <span class="o">=</span> <span class="nc">BNN</span><span class="p">(</span><span class="n">layer_units</span> <span class="o">=</span> <span class="n">layers</span><span class="p">,</span>
                           <span class="n">activation_func</span> <span class="o">=</span> <span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)</span>
        
        <span class="c1"># trainable variables for the standard distribution 
</span>        <span class="n">self</span><span class="p">.</span><span class="n">std_alpha</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nc">Variable</span><span class="p">([</span><span class="mf">10.0</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">std_alpha</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">std_beta</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nc">Variable</span><span class="p">([</span><span class="mf">10.0</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">std_beta</span><span class="sh">'</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">total_samples</span> <span class="o">=</span> <span class="n">total_samples</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">training</span> <span class="o">=</span> <span class="bp">True</span><span class="p">):</span>

        <span class="c1"># Predict mean
</span>        <span class="n">loc_preds</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">loc_net</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span> <span class="o">=</span> <span class="n">training</span><span class="p">)</span>
        
        <span class="c1"># Predict std deviation using Gamma
</span>        <span class="n">std_gamma</span> <span class="o">=</span> <span class="n">tfp</span><span class="p">.</span><span class="n">distributions</span><span class="p">.</span><span class="nc">Gamma</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">std_alpha</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">std_beta</span><span class="p">)</span>
        
        <span class="n">inverse_sqrt_transform</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="nf">reciprocal</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">N</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">training</span><span class="p">:</span>
            <span class="c1"># transforms the precision sampled from the gamma distribution to standard deviation.
</span>            <span class="n">std_preds</span> <span class="o">=</span> <span class="nf">inverse_sqrt_transform</span><span class="p">(</span><span class="n">std_gamma</span><span class="p">.</span><span class="nf">sample</span><span class="p">([</span><span class="n">N</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">gamma_sample</span><span class="sh">'</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">std_preds</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">ones</span><span class="p">([</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">*</span><span class="nf">inverse_sqrt_transform</span><span class="p">(</span><span class="n">std_gamma</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">gamma_sample</span><span class="sh">'</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">loc_preds</span><span class="p">,</span> <span class="n">std_preds</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span>
        <span class="n">elbo_loss</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_train_evaluate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">y_loc_pred</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>

        <span class="n">self</span><span class="p">.</span><span class="n">train_mae_tracker</span><span class="p">.</span><span class="nf">update_state</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_loc_pred</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">train_elbo_tracker</span><span class="p">.</span><span class="nf">update_state</span><span class="p">(</span><span class="n">elbo_loss</span><span class="p">)</span> 

        <span class="n">dict_losses</span> <span class="o">=</span> <span class="p">{</span> <span class="sh">"</span><span class="s">train_mae</span><span class="sh">"</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">train_mae_tracker</span><span class="p">.</span><span class="nf">result</span><span class="p">(),</span> 
                        <span class="sh">"</span><span class="s">train_elbo</span><span class="sh">"</span><span class="p">:</span><span class="n">self</span><span class="p">.</span><span class="n">train_elbo_tracker</span><span class="p">.</span><span class="nf">result</span><span class="p">()}</span>
        <span class="k">return</span> <span class="n">dict_losses</span>

    <span class="nd">@tf.function</span>
    <span class="k">def</span> <span class="nf">_train_evaluate</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span>  <span class="n">y</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nc">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">log_likelihoods</span><span class="p">,</span> <span class="n">preds</span>  <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">log_likelihood</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">elbo_loss</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">total_kl_loss</span><span class="o">/</span><span class="n">self</span><span class="p">.</span><span class="n">total_samples</span>  <span class="o">-</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">log_likelihoods</span><span class="p">)</span>

        <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="p">.</span><span class="nf">gradient</span><span class="p">(</span><span class="n">elbo_loss</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">trainable_weights</span><span class="p">)</span>  
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span> <span class="o">!=</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">apply_gradients</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">trainable_weights</span><span class="p">))</span>       

        <span class="k">return</span> <span class="n">elbo_loss</span><span class="p">,</span> <span class="n">preds</span>
    
    <span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span>
        <span class="n">elbo_loss</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_test_evaluate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">y_loc_pred</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">val_mae_tracker</span><span class="p">.</span><span class="nf">update_state</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_loc_pred</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">val_elbo_tracker</span><span class="p">.</span><span class="nf">update_state</span><span class="p">(</span><span class="n">elbo_loss</span><span class="p">)</span> 

        <span class="n">dict_losses</span> <span class="o">=</span> <span class="p">{</span> <span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">val_mae_tracker</span><span class="p">.</span><span class="nf">result</span><span class="p">(),</span> 
                        <span class="sh">"</span><span class="s">elbo</span><span class="sh">"</span><span class="p">:</span><span class="n">self</span><span class="p">.</span><span class="n">val_elbo_tracker</span><span class="p">.</span><span class="nf">result</span><span class="p">()}</span>
        <span class="k">return</span> <span class="n">dict_losses</span>
    
    <span class="nd">@tf.function</span>
    <span class="k">def</span> <span class="nf">_test_evaluate</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">log_likelihoods</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">log_likelihood</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">elbo_loss</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">total_kl_loss</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">total_samples</span> <span class="o">-</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">log_likelihoods</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">elbo_loss</span><span class="p">,</span> <span class="n">preds</span>   

    <span class="k">def</span> <span class="nf">log_likelihood</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">training</span> <span class="o">=</span> <span class="bp">True</span><span class="p">):</span>
        
        <span class="n">preds</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">call</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span> <span class="o">=</span> <span class="n">training</span><span class="p">)</span>
        
        <span class="c1"># Ensure consistent dtypes
</span>        <span class="n">loc</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">preds</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">preds</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">y</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        
        <span class="n">log_likelihood</span> <span class="o">=</span> <span class="n">tfd</span><span class="p">.</span><span class="nc">Normal</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">std</span><span class="p">).</span><span class="nf">log_prob</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span>  <span class="n">log_likelihood</span><span class="p">,</span> <span class="n">preds</span>
    
    <span class="nd">@tf.function</span>
    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">call</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">preds</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">preds</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tfp</span><span class="p">.</span><span class="n">distributions</span><span class="p">.</span><span class="nc">Normal</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">std</span><span class="p">).</span><span class="nf">sample</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">samples</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">n_sample</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">N</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">n_sample</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_sample</span><span class="p">):</span>
            <span class="n">samples</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">samples</span>
    
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">total_kl_loss</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="c1"># KL loss from the mean based on data
</span>        <span class="n">loc_kl_loss</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">loc_net</span><span class="p">.</span><span class="n">network_losses</span>

        <span class="c1"># KL loss from the standard deviation based on data
</span>        <span class="n">prior</span>  <span class="o">=</span> <span class="n">tfp</span><span class="p">.</span><span class="n">distributions</span><span class="p">.</span><span class="nc">Gamma</span><span class="p">(</span><span class="mf">10.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">)</span>  <span class="c1">#prior is fixed 
</span>        <span class="n">posterior</span> <span class="o">=</span> <span class="n">tfp</span><span class="p">.</span><span class="n">distributions</span><span class="p">.</span><span class="nc">Gamma</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">std_alpha</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">std_beta</span><span class="p">)</span>
        <span class="n">std_kl_loss</span> <span class="o">=</span> <span class="n">tfp</span><span class="p">.</span><span class="n">distributions</span><span class="p">.</span><span class="nf">kl_divergence</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span> <span class="n">prior</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loc_kl_loss</span> <span class="o">+</span> <span class="n">std_kl_loss</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bnn_regressor</span> <span class="o">=</span> <span class="nc">BNNRegressor</span><span class="p">([</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span> <span class="n">total_samples</span><span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">bnn_regressor</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">))</span>
<span class="n">bnn_history</span> <span class="o">=</span> <span class="n">bnn_regressor</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> 
                                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">Y_val</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">]),</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Save Model
</span><span class="n">bnn_regressor</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">current_directory</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="nf">getcwd</span><span class="p">()</span>
<span class="n">save_dir</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">expanduser</span><span class="p">(</span> <span class="n">current_directory</span> <span class="o">+</span> <span class="sh">'</span><span class="s">/models/bnn_regressor</span><span class="sh">'</span><span class="p">)</span>
<span class="n">bnn_regressor</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">save_dir</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/150
382/382 [==============================] - 39s 96ms/step - train_mae: 0.5887 - train_elbo: 9.8080 
                                                         - val_mae: 0.4213 - val_elbo: 9.6058
Epoch 2/150
382/382 [==============================] - 36s 95ms/step - train_mae: 0.4066 - train_elbo: 9.5929 
                                                         - val_mae: 0.3969 - val_elbo: 9.5314
Epoch 3/150
382/382 [==============================] - 37s 96ms/step - train_mae: 0.3951 - train_elbo: 9.5266 
                                                         - val_mae: 0.3918 - val_elbo: 9.4699
.
.
.
Epoch 150/150
382/382 [==============================] - 36s 95ms/step - train_mae: 0.3714 - train_elbo: 3.2719 
                                                         - val_mae: 0.3659 - val_elbo: 3.2391
12202/12202 [==============================] - 12s 956us/step
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">bnn_history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">train_mae</span><span class="sh">'</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Train</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">bnn_history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">val_mae</span><span class="sh">'</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">#d08f10ff</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Validation</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Epoch</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Mean Absolute Error</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">MAE vs Epochs</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">grid</span><span class="p">()</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">bnn_history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">train_elbo</span><span class="sh">'</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Train</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">bnn_history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">val_elbo</span><span class="sh">'</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">#d08f10ff</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Validation</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Epoch</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">ELBO</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">ELBO vs Epochs</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">grid</span><span class="p">()</span>


<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<center>
<img src="/assets/img/post6/bnn_lr_elbo_curve.png" width="800" height="400" />
</center>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bnn_preds</span> <span class="o">=</span> <span class="n">bnn_regressor</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># distributions plot
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># KDE plot for residuals
</span><span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">kdeplot</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">#dfdc7bff</span><span class="sh">"</span> <span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">True</span><span class="sh">'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">kdeplot</span><span class="p">(</span><span class="n">bnn_preds</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">fill</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">#d08f10ff</span><span class="sh">"</span><span class="p">,</span>  <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Predicted</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Density</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Distribution (KDE)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># CDF plot
</span><span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">kdeplot</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">cumulative</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">#dfdc7bff</span><span class="sh">"</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">True</span><span class="sh">'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">kdeplot</span><span class="p">(</span><span class="n">bnn_preds</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">cumulative</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">#d08f10ff</span><span class="sh">"</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>  <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Predicted</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">CDF</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Cumulative Distribution (CDF)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>12202/12202 [==============================] - 15s 1ms/step
</code></pre></div></div>

<center>
<img src="/assets/img/post6/bnn_distribution_true_predict.png" width="800" height="300" />
</center>

<p>The BNN get a very good result similar to the simple neural network. However, there is a limitation with this approach: while the gamma distribution parameters are trainable, they do not vary based on the input data. This means that the model learns a single pair of $\alpha$ and $\beta$ values to represent the uncertainty across all predictions, leading to a constant level of uncertainty.  This approach assumes that the uncertainty is the same regardless of the input features, which is often not the case in real-world scenarios. Different input data points can have varying levels of uncertainty, and a model that assumes constant uncertainty might not capture the true underlying variability.</p>

<h1 id="two-heads-bayesian-neural-network"><strong>Two Heads Bayesian Neural Network</strong></h1>

<p>To enable our BNN to predict both the target value and the associated uncertainty, we can use a more advanced approach that makes the standard deviation dependent on the input data. This approach involves employing two separate neural networks within the BNN architecture. One network is responsible for predicting the mean value $\mu$ of the target distribution based on the input features $\mathbf{x}$, while the other network predicts the standard deviation $\sigma$, representing the uncertainty of the predictions.</p>

<center>
<img src="/assets/img/post6/2head-bnn.svg" width="800" height="600" />
</center>

<p>In the image provided, the input data $\mathbf{x}$ is processed through a shared initial set of layers (in red), which then splits into two distinct pathways. The upper pathway (in green) is responsible for predicting the mean $\mu$. The lower pathway (in blue) is dedicated to predicting the standard deviation $\sigma$.By using these two networks, the model can capture varying levels of uncertainty across different regions of the input space. The uncertainty prediction network ensures that the standard deviation is not a fixed value but varies according to the input data, leading to more accurate and reliable uncertainty estimates. This dual-network approach allows the BNN to provide a comprehensive understanding of both the predicted target value and the associated uncertainty.</p>

<p>Having defined the BNN class and the layer class from the previously model, it’s relatively easy to define another class which implements the Two Heads Bayesian density network. We can just define a core network consisting of several layers (in red), and then two sub-networks which receive the output of the core network and output independent predictions. The output of one network we’ll use as the mean predictions, and the output of the other as the standard deviation predictions.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">DualBNNRegressor</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Multilayer fully-connected Bayesian neural network, with two heads to predict
    both the mean and the standard deviation of the output distribution.

    Parameters
    ----------
    units : List[int]
        Number of output dimensions for each layer in the core network.
    head_units : List[int]
        Number of output dimensions for each layer in the head networks.
    name : None or str
        Name for the layer.
    </span><span class="sh">"""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">core_units</span><span class="p">,</span> <span class="n">head_units</span><span class="p">,</span> <span class="n">total_samples</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
        <span class="c1"># Initialize the parent class
</span>        <span class="nf">super</span><span class="p">(</span><span class="n">DualBNNRegressor</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="p">)</span>

        <span class="c1"># Trackers for training metrics
</span>        <span class="n">self</span><span class="p">.</span><span class="n">train_elbo_tracker</span> <span class="o">=</span> <span class="nc">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">train_elbo</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">train_mae_tracker</span> <span class="o">=</span> <span class="nc">MeanAbsoluteError</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">train_mae</span><span class="sh">'</span><span class="p">)</span>

        <span class="c1"># Trackers for validation metrics
</span>        <span class="n">self</span><span class="p">.</span><span class="n">val_elbo_tracker</span> <span class="o">=</span> <span class="nc">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">val_elbo</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">val_mae_tracker</span> <span class="o">=</span> <span class="nc">MeanAbsoluteError</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">val_mae</span><span class="sh">'</span><span class="p">)</span>

        <span class="c1"># Create the core network using BayesianNN
</span>        <span class="n">self</span><span class="p">.</span><span class="n">core_net</span> <span class="o">=</span> <span class="nc">BNN</span><span class="p">(</span> <span class="n">layer_units</span> <span class="o">=</span> <span class="n">core_units</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> 
                                    <span class="n">output_unit</span> <span class="o">=</span> <span class="n">core_units</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> 
                                    <span class="n">activation_func</span> <span class="o">=</span> <span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)</span> 
        
        <span class="c1"># Create the loc(mean) head network
</span>        <span class="n">self</span><span class="p">.</span><span class="n">loc_net</span> <span class="o">=</span> <span class="nc">BNN</span><span class="p">(</span>  <span class="n">layer_units</span> <span class="o">=</span> <span class="p">[</span><span class="n">core_units</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span> <span class="o">+</span> <span class="n">head_units</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> 
                                    <span class="n">output_unit</span> <span class="o">=</span> <span class="n">head_units</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                    <span class="n">activation_func</span> <span class="o">=</span> <span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)</span>    

        <span class="c1"># Create the scale (standard deviation) head network
</span>        <span class="n">self</span><span class="p">.</span><span class="n">std_net</span> <span class="o">=</span> <span class="nc">BNN</span><span class="p">(</span>  <span class="n">layer_units</span> <span class="o">=</span> <span class="p">[</span><span class="n">core_units</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span> <span class="o">+</span> <span class="n">head_units</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> 
                                    <span class="n">output_unit</span> <span class="o">=</span> <span class="n">head_units</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>  
                                    <span class="n">output_activation</span> <span class="o">=</span>  <span class="sh">'</span><span class="s">softplus</span><span class="sh">'</span><span class="p">,</span>
                                    <span class="n">activation_func</span> <span class="o">=</span> <span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)</span> 
        
        <span class="n">self</span><span class="p">.</span><span class="n">total_samples</span> <span class="o">=</span> <span class="n">total_samples</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">training</span> <span class="o">=</span> <span class="bp">True</span><span class="p">):</span>

        <span class="sh">"""</span><span class="s">
        Executes a forward pass through the network.

        Args:
            x (Tensor): The input tensor.

        Returns:
            Tensor: The output of the network after passing through all the layers.
        </span><span class="sh">"""</span>
        <span class="c1"># Pass the input through the core network
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">core_net</span><span class="p">(</span><span class="n">x</span><span class="p">,</span>  <span class="n">training</span> <span class="o">=</span> <span class="n">training</span><span class="p">)</span>

        <span class="c1"># Pass the output of the core network through the location and std heads
</span>        <span class="n">loc_preds</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">loc_net</span><span class="p">(</span><span class="n">x</span><span class="p">,</span>  <span class="n">training</span> <span class="o">=</span> <span class="n">training</span><span class="p">)</span>
        <span class="n">std_preds</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">std_net</span><span class="p">(</span><span class="n">x</span><span class="p">,</span>  <span class="n">training</span> <span class="o">=</span> <span class="n">training</span><span class="p">)</span>
            
        <span class="c1"># Return the output of the location and std heads
</span>        <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">loc_preds</span><span class="p">,</span> <span class="n">std_preds</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
    

    <span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span>
        <span class="n">elbo_loss</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_train_evaluate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">y_loc_pred</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>

        <span class="n">self</span><span class="p">.</span><span class="n">train_mae_tracker</span><span class="p">.</span><span class="nf">update_state</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_loc_pred</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">train_elbo_tracker</span><span class="p">.</span><span class="nf">update_state</span><span class="p">(</span><span class="n">elbo_loss</span><span class="p">)</span> 

        <span class="n">dict_losses</span> <span class="o">=</span> <span class="p">{</span> <span class="sh">"</span><span class="s">train_mae</span><span class="sh">"</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">train_mae_tracker</span><span class="p">.</span><span class="nf">result</span><span class="p">(),</span> 
                        <span class="sh">"</span><span class="s">train_elbo</span><span class="sh">"</span><span class="p">:</span><span class="n">self</span><span class="p">.</span><span class="n">train_elbo_tracker</span><span class="p">.</span><span class="nf">result</span><span class="p">()}</span>
        <span class="k">return</span> <span class="n">dict_losses</span>
    
    <span class="nd">@tf.function</span>
    <span class="k">def</span> <span class="nf">_train_evaluate</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span>  <span class="n">y</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nc">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">log_likelihoods</span><span class="p">,</span> <span class="n">preds</span>  <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">log_likelihood</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">elbo_loss</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">total_kl_loss</span><span class="o">/</span><span class="n">self</span><span class="p">.</span><span class="n">total_samples</span>  <span class="o">-</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">log_likelihoods</span><span class="p">)</span>

        <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="p">.</span><span class="nf">gradient</span><span class="p">(</span><span class="n">elbo_loss</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">trainable_weights</span><span class="p">)</span>  
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span> <span class="o">!=</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">apply_gradients</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">trainable_weights</span><span class="p">))</span>       

        <span class="k">return</span> <span class="n">elbo_loss</span><span class="p">,</span> <span class="n">preds</span>
    
    <span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span>
        <span class="n">elbo_loss</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_test_evaluate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">y_loc_pred</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">val_mae_tracker</span><span class="p">.</span><span class="nf">update_state</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_loc_pred</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">val_elbo_tracker</span><span class="p">.</span><span class="nf">update_state</span><span class="p">(</span><span class="n">elbo_loss</span><span class="p">)</span> 

        <span class="n">dict_losses</span> <span class="o">=</span> <span class="p">{</span> <span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">val_mae_tracker</span><span class="p">.</span><span class="nf">result</span><span class="p">(),</span> 
                        <span class="sh">"</span><span class="s">elbo</span><span class="sh">"</span><span class="p">:</span><span class="n">self</span><span class="p">.</span><span class="n">val_elbo_tracker</span><span class="p">.</span><span class="nf">result</span><span class="p">()}</span>
        <span class="k">return</span> <span class="n">dict_losses</span>
    
    <span class="nd">@tf.function</span>
    <span class="k">def</span> <span class="nf">_test_evaluate</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">log_likelihoods</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">log_likelihood</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">elbo_loss</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">total_kl_loss</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">total_samples</span> <span class="o">-</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">log_likelihoods</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">elbo_loss</span><span class="p">,</span> <span class="n">preds</span>

     
    <span class="k">def</span> <span class="nf">log_likelihood</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">training</span> <span class="o">=</span> <span class="bp">True</span><span class="p">):</span>
        
        <span class="n">preds</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">call</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span> <span class="o">=</span> <span class="n">training</span><span class="p">)</span>
        <span class="c1"># Ensure consistent dtypes
</span>        <span class="n">loc</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">preds</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">preds</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">y</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        
        <span class="n">log_likelihood</span> <span class="o">=</span> <span class="n">tfd</span><span class="p">.</span><span class="nc">Normal</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">std</span><span class="p">).</span><span class="nf">log_prob</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="c1"># Return log likelihood of true df_taxi given predictions
</span>        <span class="k">return</span>  <span class="n">log_likelihood</span><span class="p">,</span> <span class="n">preds</span>
    
    
    <span class="nd">@tf.function</span>
    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">call</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">loc</span><span class="p">,</span> <span class="n">std</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">preds</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">tfp</span><span class="p">.</span><span class="n">distributions</span><span class="p">.</span><span class="nc">Normal</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">std</span><span class="p">).</span><span class="nf">sample</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">samples</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">n_sample</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">N</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">n_sample</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_sample</span><span class="p">):</span>
           <span class="n">samples</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">samples</span>
    
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">total_kl_loss</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="c1"># KL-loss from the networks
</span>        <span class="n">core_kl_loss</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">core_net</span><span class="p">.</span><span class="n">network_losses</span>
        <span class="n">loc_kl_loss</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">loc_net</span><span class="p">.</span><span class="n">network_losses</span>
        <span class="n">std_kl_loss</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">std_net</span><span class="p">.</span><span class="n">network_losses</span>
        <span class="k">return</span> <span class="n">core_kl_loss</span> <span class="o">+</span> <span class="n">loc_kl_loss</span> <span class="o">+</span> <span class="n">std_kl_loss</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c1"># Initialize and compile the model
</span><span class="n">dual_bnn_regressor</span> <span class="o">=</span> <span class="nc">DualBNNRegressor</span><span class="p">([</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">128</span><span class="p">],</span> <span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">dual_bnn_regressor</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">))</span>

<span class="c1"># Train the model using the manually created datasets
</span><span class="n">dualbnn_history</span> <span class="o">=</span> <span class="n">dual_bnn_regressor</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> 
                                        <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">Y_val</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">]),</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>


<span class="c1"># Save Model
</span><span class="n">dual_bnn_regressor</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">current_directory</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="nf">getcwd</span><span class="p">()</span>
<span class="n">save_dir</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">expanduser</span><span class="p">(</span> <span class="n">current_directory</span> <span class="o">+</span> <span class="sh">'</span><span class="s">/models/dual_bnn_regressor</span><span class="sh">'</span><span class="p">)</span>
<span class="n">dual_bnn_regressor</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">save_dir</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/150
382/382 [==============================] - 45s 108ms/step - train_mae: 0.5348 - train_elbo: 10.2264 
                                                          - val_mae: 0.4071 - val_elbo: 9.8879
Epoch 2/150
382/382 [==============================] - 40s 105ms/step - train_mae: 0.3995 - train_elbo: 9.8348 
                                                          - val_mae: 0.3921 - val_elbo: 9.7848
Epoch 3/150
382/382 [==============================] - 40s 105ms/step - train_mae: 0.3906 - train_elbo: 9.7540 
                                                          - val_mae: 0.3872 - val_elbo: 9.7205
.
.
.
Epoch 150/150
382/382 [==============================] - 40s 104ms/step - train_mae: 0.3626 - train_elbo: 4.9003 
                                                          - val_mae: 0.3620 - val_elbo: 4.8932
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">dualbnn_history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">train_mae</span><span class="sh">'</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Train</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">dualbnn_history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">val_mae</span><span class="sh">'</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">#d08f10ff</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Validation</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Epoch</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Mean Absolute Error</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">MAE vs Epochs</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">grid</span><span class="p">()</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">dualbnn_history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">train_elbo</span><span class="sh">'</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Train</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">dualbnn_history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">val_elbo</span><span class="sh">'</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">#d08f10ff</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Validation</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Epoch</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">ELBO</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">ELBO vs Epochs</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">grid</span><span class="p">()</span>


<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<center>
<img src="/assets/img/post6/dualbnn_lr_elbo_curve.png" width="800" height="400" />
</center>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dual_bnn_preds</span> <span class="o">=</span> <span class="n">dual_bnn_regressor</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># distributions plot
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># KDE plot for residuals
</span><span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">kdeplot</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">#dfdc7bff</span><span class="sh">"</span> <span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">True</span><span class="sh">'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">kdeplot</span><span class="p">(</span><span class="n">dual_bnn_preds</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">fill</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">#d08f10ff</span><span class="sh">"</span><span class="p">,</span>  <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Predicted</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Density</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Distribution (KDE)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># CDF plot
</span><span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">kdeplot</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">cumulative</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">#dfdc7bff</span><span class="sh">"</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">True</span><span class="sh">'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">kdeplot</span><span class="p">(</span><span class="n">dual_bnn_preds</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">cumulative</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">#d08f10ff</span><span class="sh">"</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>  <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Predicted</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">CDF</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Cumulative Distribution (CDF)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>12202/12202 [==============================] - 20s 2ms/step
</code></pre></div></div>

<center>
<img src="/assets/img/post6/dualbnn_distribution_true_predict.png" width="800" height="300" />
</center>

<h1 id="conclusion"><strong>Conclusion</strong></h1>

<p>Now let’s compare the models we trained in terms of their predictive performance and their uncertainty estimates.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load Models
</span><span class="n">current_directory</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="nf">getcwd</span><span class="p">()</span>
<span class="n">nn_path</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">expanduser</span><span class="p">(</span> <span class="n">current_directory</span> <span class="o">+</span> <span class="sh">'</span><span class="s">/models/nn_regressor</span><span class="sh">'</span><span class="p">)</span>
<span class="n">bnn_path</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">expanduser</span><span class="p">(</span> <span class="n">current_directory</span> <span class="o">+</span> <span class="sh">'</span><span class="s">/models/bnn_regressor</span><span class="sh">'</span><span class="p">)</span>
<span class="n">dual_bnn_path</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">expanduser</span><span class="p">(</span> <span class="n">current_directory</span> <span class="o">+</span> <span class="sh">'</span><span class="s">/models/dual_bnn_regressor</span><span class="sh">'</span><span class="p">)</span>


<span class="n">nn_regressor</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="nf">load_model</span><span class="p">(</span><span class="n">nn_path</span><span class="p">,</span> 
                            <span class="n">custom_objects</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">NNRegressor</span><span class="sh">'</span><span class="p">:</span> <span class="n">NNRegressor</span><span class="p">})</span>
<span class="n">bnn_regressor</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="nf">load_model</span><span class="p">(</span><span class="n">bnn_path</span><span class="p">,</span> 
                            <span class="n">custom_objects</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">DenseFlipout</span><span class="sh">'</span><span class="p">:</span> <span class="n">DenseFlipout</span><span class="p">,</span> 
                                            <span class="sh">'</span><span class="s">BNN</span><span class="sh">'</span><span class="p">:</span> <span class="n">BNN</span><span class="p">,</span> <span class="sh">'</span><span class="s">BNNRegressor</span><span class="sh">'</span><span class="p">:</span> <span class="n">BNNRegressor</span><span class="p">})</span>
<span class="n">dual_bnn_regressor</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="nf">load_model</span><span class="p">(</span><span class="n">dual_bnn_path</span><span class="p">,</span> 
                            <span class="n">custom_objects</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">DenseFlipout</span><span class="sh">'</span><span class="p">:</span> <span class="n">DenseFlipout</span><span class="p">,</span> <span class="sh">'</span><span class="s">BNN</span><span class="sh">'</span><span class="p">:</span> <span class="n">BNN</span><span class="p">,</span> 
                                            <span class="sh">'</span><span class="s">DualBNNRegressor</span><span class="sh">'</span><span class="p">:</span> <span class="n">DualBNNRegressor</span><span class="p">})</span>

</code></pre></div></div>

<h2 id="learning-curves">Learning Curves</h2>

<p>The learning curves is very close, with the Dual BNN having the lower error.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Plot error vs epoch curves for all 3 models
</span><span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">nn_history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">val_loss</span><span class="sh">'</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">black</span><span class="sh">"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">NN</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">bnn_history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">val_mae</span><span class="sh">'</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">#dfdc7bff</span><span class="sh">"</span> <span class="p">,</span>   <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">BNN</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">dualbnn_history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">val_mae</span><span class="sh">'</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">#d08f10ff</span><span class="sh">"</span> <span class="p">,</span>  <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Dual BNN</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">MAE vs Epochs</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Epoch</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Mean Absolute Error</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

</code></pre></div></div>

<center>
<img src="/assets/img/post6/lr_all_models.png" width="600" height="400" />
</center>

<h2 id="residuals">Residuals</h2>

<p>The plots display the residual distributions for two different models: a simple Bayesian neural network (BNN) and a Two Heads Bayesian neural network (Dual BNN). Residuals are the differences between the true values and the predicted values for each model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bnn_pred_test</span><span class="o">=</span> <span class="n">bnn_regressor</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">dual_bnn_pred_test</span> <span class="o">=</span> <span class="n">dual_bnn_regressor</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Calculate residuals
</span><span class="n">resids1</span> <span class="o">=</span> <span class="n">Y_test</span> <span class="o">-</span> <span class="n">bnn_pred_test</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">resids2</span> <span class="o">=</span> <span class="n">Y_test</span> <span class="o">-</span> <span class="n">dual_bnn_pred_test</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>

<span class="c1"># Plot residual distributions using KDE and CDF
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># KDE plot for residuals
</span><span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">kdeplot</span><span class="p">(</span><span class="n">resids1</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">#dfdc7bff</span><span class="sh">"</span> <span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">BNN</span><span class="sh">'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">kdeplot</span><span class="p">(</span><span class="n">resids2</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">#d08f10ff</span><span class="sh">"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Dual BNN</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Residuals</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Density</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Residual Distributions (KDE)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># CDF plot for residuals
</span><span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">kdeplot</span><span class="p">(</span><span class="n">resids1</span><span class="p">,</span> <span class="n">cumulative</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">#dfdc7bff</span><span class="sh">"</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">BNN</span><span class="sh">'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">kdeplot</span><span class="p">(</span><span class="n">resids2</span><span class="p">,</span> <span class="n">cumulative</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">#d08f10ff</span><span class="sh">"</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Dual BNN</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Residuals</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">CDF</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Residual Distributions (CDF)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>12202/12202 [==============================] - 18s 1ms/step
12202/12202 [==============================] - 17s 1ms/step
</code></pre></div></div>

<center>
<img src="/assets/img/post6/residual_distribution_bnn_dualbnn.png" width="800" height="300" />
</center>

<p>The close overlap of the distributions indicates that the residuals from both models are similar. This similarity is expected because both models use the same network structure for predicting the mean values, even though their weights may differ. The alignment between the BNN and Dual BNN mean predictions indicates that both models are capturing the underlying patterns in the data similarly.</p>

<h2 id="predictive-distributions">Predictive Distributions</h2>

<p>The sampling process in Bayesian neural networks involves drawing samples from the posterior distribution of the network’s weights. This allows us to capture the uncertainty in the model’s predictions. During prediction, we draw samples from the posterior distribution of the weights.</p>

<p>For each input data point, we generate multiple predictions by sampling different sets of weights from the posterior distribution. The resulting set of predictions forms a predictive distribution, which reflects the model’s uncertainty about the prediction. Each sample of weights results in a different prediction for the same input data. This process captures the variability in the model’s predictions due to uncertainty in the weights.</p>

<p>To understand the predictive distributions of the Bayesian neural network (BNN) and the Two Heads Bayesian neural network (Dual BNN), we sample predictions for a subset of the test data as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Sample a subset of the test data
</span><span class="n">subset_size</span> <span class="o">=</span> <span class="mi">100000</span>  <span class="c1"># Using a smaller subset
</span><span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">subset_size</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">X_test_subset</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
<span class="n">Y_test_subset</span> <span class="o">=</span> <span class="n">Y_test</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>

<span class="c1"># Create the dataset for the subset
</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="nf">from_tensor_slices</span><span class="p">(</span><span class="n">X_test_subset</span><span class="p">).</span><span class="nf">batch</span><span class="p">(</span><span class="n">subset_size</span><span class="p">)</span>

<span class="c1"># Iterate through the dataset batches with progress bar
</span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sh">"</span><span class="s">Processing Batches</span><span class="sh">"</span><span class="p">):</span>
    <span class="n">bnn_samples</span> <span class="o">=</span> <span class="n">bnn_regressor</span><span class="p">.</span><span class="nf">samples</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">n_sample</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    <span class="n">dual_bnn_samples</span> <span class="o">=</span> <span class="n">dual_bnn_regressor</span><span class="p">.</span><span class="nf">samples</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">n_sample</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Processing Batches:   0%|          | 0/1 [00:00&lt;?, ?it/s]
Processing Batches: 100%|██████████| 1/1 [2:43:00&lt;00:00, 9780.35s/it]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dual_bnn_pred_subset</span> <span class="o">=</span> <span class="n">dual_bnn_regressor</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test_subset</span><span class="p">)</span>

<span class="c1"># Randomly select 8 unique sample indices
</span><span class="n">num_samples</span> <span class="o">=</span> <span class="n">bnn_samples</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">random_indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># Plot predictive distributions
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sample_index</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">random_indices</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">sns</span><span class="p">.</span><span class="nf">kdeplot</span><span class="p">(</span><span class="n">bnn_samples</span><span class="p">[</span><span class="n">sample_index</span><span class="p">,</span> <span class="p">:],</span> <span class="n">fill</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">#dfdc7bff</span><span class="sh">"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">BNN</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">sns</span><span class="p">.</span><span class="nf">kdeplot</span><span class="p">(</span><span class="n">dual_bnn_samples</span><span class="p">[</span><span class="n">sample_index</span><span class="p">,</span> <span class="p">:],</span> <span class="n">fill</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">#d08f10ff</span><span class="sh">"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Dual BNN</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">axvline</span><span class="p">(</span><span class="n">dual_bnn_pred_subset</span><span class="p">[</span><span class="n">sample_index</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">#d08f10ff</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Dual BNN Predict</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">axvline</span><span class="p">(</span><span class="n">Y_test_subset</span><span class="p">[</span><span class="n">sample_index</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="sh">'</span><span class="s">:</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">True</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">])</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Sample </span><span class="si">{</span><span class="n">sample_index</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">gca</span><span class="p">().</span><span class="nf">get_yaxis</span><span class="p">().</span><span class="nf">set_ticklabels</span><span class="p">([])</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">6</span><span class="p">:</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">gca</span><span class="p">().</span><span class="nf">get_xaxis</span><span class="p">().</span><span class="nf">set_ticklabels</span><span class="p">([])</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
        
        
<span class="c1">#plt.tight_layout()
</span><span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>3125/3125 [==============================] - 4s 1ms/step
</code></pre></div></div>

<center>
<img src="/assets/img/post6/predicted_trip_distributions.png" width="800" height="600" />
</center>

<p>The density plots for individual samples illustrate that both the simple Bayesian neural network (BNN) and the Two Heads Bayesian neural network (Dual BNN) provide accurate predictions. However, the Dual BNN offers the additional benefit of varying uncertainty estimates, making it more informative in terms of prediction confidence. The BNN, while still effective, provides more consistent uncertainty estimates, potentially limiting its utility in scenarios where understanding prediction confidence is crucial.</p>

<p>Notice how the Two Heads network (orange) varies its uncertainty estimates, unlike the model which doesn’t estimate uncertainty (yellow). For example, in samples 24592, 91723, and 11044, the Two Heads network is much more certain of its estimate than the other model, showing a high peak with a much sharper curve around the predicted mean for the distribution in orange. On the other hand, samples 54662, 24663, and 32918 show less certain estimates, and the predictive distribution is wider. Sometimes both models have similar levels of uncertainty, like in samples 54662 and 32918.</p>


  
    
<div id="disqus_thread"></div>
<script>
    /**
    *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
    *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables    */
    /*
    var disqus_config = function () {
    this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://https-marcosbenicio-github-io-1.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>



</div>


    </div>

  </body>
</html>
